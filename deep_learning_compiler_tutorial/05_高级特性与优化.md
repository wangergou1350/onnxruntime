# 第五阶段：高级特性与优化

## 概述

第五阶段将实现 MiniTVM 的高级特性，包括自动微分、自动调度、混合精度计算等。这些特性使深度学习编译器能够处理更复杂的模型和优化场景。

## 实现计划

### Day 23-24: 自动微分系统
### Day 25-26: 自动调度与搜索
### Day 27: 混合精度与量化

---

## Day 23-24: 自动微分系统

### 自动微分基础框架

```cpp
// include/minitvm/autodiff/autodiff_base.h
#pragma once

#include "minitvm/core/graph.h"
#include "minitvm/core/tensor.h"
#include <unordered_map>
#include <functional>

namespace minitvm {
namespace autodiff {

// 梯度信息
struct GradientInfo {
    NodePtr forward_node;
    NodePtr gradient_node;
    bool requires_grad = true;
    bool retain_graph = false;
};

// 自动微分上下文
class AutoDiffContext {
public:
    AutoDiffContext() = default;
    
    // 启用/禁用梯度计算
    void set_grad_enabled(bool enabled) { grad_enabled_ = enabled; }
    bool is_grad_enabled() const { return grad_enabled_; }
    
    // 记录操作
    void record_operation(NodePtr node, const std::vector<NodePtr>& inputs);
    
    // 梯度信息管理
    void set_requires_grad(NodePtr node, bool requires_grad = true);
    bool requires_grad(NodePtr node) const;
    
    void set_gradient(NodePtr node, NodePtr grad);
    NodePtr get_gradient(NodePtr node) const;
    
    // 计算图管理
    void retain_graph(bool retain = true) { retain_graph_ = retain; }
    bool should_retain_graph() const { return retain_graph_; }
    
    void clear_gradients();
    
private:
    bool grad_enabled_ = true;
    bool retain_graph_ = false;
    std::unordered_map<NodePtr, GradientInfo> gradient_info_;
    std::vector<NodePtr> tape_;  // 记录前向计算的操作序列
};

// 全局自动微分上下文
AutoDiffContext& get_global_context();

// RAII风格的梯度开关
class NoGradGuard {
public:
    NoGradGuard() : prev_state_(get_global_context().is_grad_enabled()) {
        get_global_context().set_grad_enabled(false);
    }
    
    ~NoGradGuard() {
        get_global_context().set_grad_enabled(prev_state_);
    }
    
private:
    bool prev_state_;
};

// 梯度计算器基类
class GradientComputer {
public:
    virtual ~GradientComputer() = default;
    
    // 计算单个操作的梯度
    virtual std::vector<NodePtr> compute_gradient(
        NodePtr output,
        NodePtr grad_output,
        const std::vector<NodePtr>& inputs
    ) = 0;
    
    // 检查是否支持该操作
    virtual bool supports_operation(const std::string& op_type) const = 0;
};

// 梯度计算器注册表
class GradientRegistry {
public:
    static GradientRegistry& instance();
    
    void register_gradient(const std::string& op_type, 
                          std::unique_ptr<GradientComputer> computer);
    
    GradientComputer* get_gradient_computer(const std::string& op_type) const;
    
    std::vector<std::string> list_supported_operations() const;
    
private:
    std::unordered_map<std::string, std::unique_ptr<GradientComputer>> computers_;
};

// 反向传播引擎
class BackwardEngine {
public:
    BackwardEngine();
    
    // 执行反向传播
    void backward(NodePtr loss, NodePtr grad_output = nullptr);
    
    // 批量反向传播
    void backward_batch(const std::vector<NodePtr>& losses,
                       const std::vector<NodePtr>& grad_outputs = {});
    
    // 计算梯度（不累积）
    std::unordered_map<NodePtr, NodePtr> compute_gradients(
        NodePtr loss,
        const std::vector<NodePtr>& variables,
        NodePtr grad_output = nullptr
    );
    
    // 高阶导数
    NodePtr compute_hessian_vector_product(NodePtr loss, NodePtr vector,
                                          const std::vector<NodePtr>& variables);
    
private:
    AutoDiffContext* context_;
    
    // 拓扑排序（反向）
    std::vector<NodePtr> reverse_topological_sort(NodePtr start);
    
    // 累积梯度
    void accumulate_gradient(NodePtr node, NodePtr grad);
    
    // 梯度聚合
    NodePtr aggregate_gradients(const std::vector<NodePtr>& grads);
};

} // namespace autodiff
} // namespace minitvm
```

### 基础操作的梯度实现

```cpp
// include/minitvm/autodiff/basic_gradients.h
#pragma once

#include "autodiff_base.h"

namespace minitvm {
namespace autodiff {

// 加法梯度
class AddGradient : public GradientComputer {
public:
    std::vector<NodePtr> compute_gradient(
        NodePtr output,
        NodePtr grad_output,
        const std::vector<NodePtr>& inputs
    ) override;
    
    bool supports_operation(const std::string& op_type) const override {
        return op_type == "Add";
    }
};

// 乘法梯度
class MulGradient : public GradientComputer {
public:
    std::vector<NodePtr> compute_gradient(
        NodePtr output,
        NodePtr grad_output,
        const std::vector<NodePtr>& inputs
    ) override;
    
    bool supports_operation(const std::string& op_type) const override {
        return op_type == "Mul";
    }
};

// 矩阵乘法梯度
class MatMulGradient : public GradientComputer {
public:
    std::vector<NodePtr> compute_gradient(
        NodePtr output,
        NodePtr grad_output,
        const std::vector<NodePtr>& inputs
    ) override;
    
    bool supports_operation(const std::string& op_type) const override {
        return op_type == "MatMul";
    }
};

// ReLU梯度
class ReLUGradient : public GradientComputer {
public:
    std::vector<NodePtr> compute_gradient(
        NodePtr output,
        NodePtr grad_output,
        const std::vector<NodePtr>& inputs
    ) override;
    
    bool supports_operation(const std::string& op_type) const override {
        return op_type == "ReLU";
    }
};

// Softmax梯度
class SoftmaxGradient : public GradientComputer {
public:
    std::vector<NodePtr> compute_gradient(
        NodePtr output,
        NodePtr grad_output,
        const std::vector<NodePtr>& inputs
    ) override;
    
    bool supports_operation(const std::string& op_type) const override {
        return op_type == "Softmax";
    }
};

// 交叉熵损失梯度
class CrossEntropyGradient : public GradientComputer {
public:
    std::vector<NodePtr> compute_gradient(
        NodePtr output,
        NodePtr grad_output,
        const std::vector<NodePtr>& inputs
    ) override;
    
    bool supports_operation(const std::string& op_type) const override {
        return op_type == "CrossEntropy";
    }
};

// 卷积梯度
class Conv2DGradient : public GradientComputer {
public:
    std::vector<NodePtr> compute_gradient(
        NodePtr output,
        NodePtr grad_output,
        const std::vector<NodePtr>& inputs
    ) override;
    
    bool supports_operation(const std::string& op_type) const override {
        return op_type == "Conv2D";
    }
    
private:
    // 输入梯度：使用卷积核的转置卷积
    NodePtr compute_input_gradient(NodePtr grad_output, NodePtr weight, 
                                  const std::vector<int>& strides,
                                  const std::vector<int>& padding);
    
    // 权重梯度：输入与梯度的卷积
    NodePtr compute_weight_gradient(NodePtr input, NodePtr grad_output,
                                   const Shape& weight_shape,
                                   const std::vector<int>& strides,
                                   const std::vector<int>& padding);
};

} // namespace autodiff
} // namespace minitvm
```

### 梯度实现示例

```cpp
// src/autodiff/basic_gradients.cpp
#include "minitvm/autodiff/basic_gradients.h"
#include "minitvm/core/graph.h"

namespace minitvm {
namespace autodiff {

std::vector<NodePtr> AddGradient::compute_gradient(
    NodePtr output,
    NodePtr grad_output,
    const std::vector<NodePtr>& inputs
) {
    // 加法的梯度：grad_output 直接传播到两个输入
    // 但需要处理广播的情况
    
    std::vector<NodePtr> grad_inputs;
    
    for (const auto& input : inputs) {
        NodePtr grad_input = grad_output;
        
        // 处理广播：如果输入形状与输出形状不同，需要求和降维
        if (input->output_shapes()[0] != output->output_shapes()[0]) {
            grad_input = handle_broadcast_gradient(grad_output, 
                                                  output->output_shapes()[0],
                                                  input->output_shapes()[0]);
        }
        
        grad_inputs.push_back(grad_input);
    }
    
    return grad_inputs;
}

std::vector<NodePtr> MulGradient::compute_gradient(
    NodePtr output,
    NodePtr grad_output,
    const std::vector<NodePtr>& inputs
) {
    assert(inputs.size() == 2);
    
    auto a = inputs[0];
    auto b = inputs[1];
    
    // 乘法的梯度：
    // grad_a = grad_output * b
    // grad_b = grad_output * a
    
    GraphBuilder builder;
    auto grad_a = builder.mul(grad_output, b);
    auto grad_b = builder.mul(grad_output, a);
    
    // 处理广播
    if (a->output_shapes()[0] != output->output_shapes()[0]) {
        grad_a = handle_broadcast_gradient(grad_a,
                                          output->output_shapes()[0],
                                          a->output_shapes()[0]);
    }
    
    if (b->output_shapes()[0] != output->output_shapes()[0]) {
        grad_b = handle_broadcast_gradient(grad_b,
                                          output->output_shapes()[0],
                                          b->output_shapes()[0]);
    }
    
    return {grad_a, grad_b};
}

std::vector<NodePtr> MatMulGradient::compute_gradient(
    NodePtr output,
    NodePtr grad_output,
    const std::vector<NodePtr>& inputs
) {
    assert(inputs.size() == 2);
    
    auto a = inputs[0];  // [M, K]
    auto b = inputs[1];  // [K, N]
    
    // 矩阵乘法的梯度：
    // grad_a = grad_output @ b.T
    // grad_b = a.T @ grad_output
    
    GraphBuilder builder;
    
    // 创建转置操作
    auto b_transpose = builder.transpose(b, {1, 0});
    auto a_transpose = builder.transpose(a, {1, 0});
    
    auto grad_a = builder.matmul(grad_output, b_transpose);
    auto grad_b = builder.matmul(a_transpose, grad_output);
    
    return {grad_a, grad_b};
}

std::vector<NodePtr> ReLUGradient::compute_gradient(
    NodePtr output,
    NodePtr grad_output,
    const std::vector<NodePtr>& inputs
) {
    assert(inputs.size() == 1);
    
    auto input = inputs[0];
    
    // ReLU的梯度：grad_output * (input > 0)
    GraphBuilder builder;
    auto zero = builder.constant(zeros_like(input->runtime_outputs()[0]));
    auto mask = builder.greater(input, zero);  // input > 0
    auto grad_input = builder.mul(grad_output, mask);
    
    return {grad_input};
}

std::vector<NodePtr> SoftmaxGradient::compute_gradient(
    NodePtr output,
    NodePtr grad_output,
    const std::vector<NodePtr>& inputs
) {
    assert(inputs.size() == 1);
    
    // Softmax的梯度比较复杂：
    // grad_input = softmax_output * (grad_output - sum(grad_output * softmax_output, axis=-1, keepdims=True))
    
    GraphBuilder builder;
    
    // softmax_output 就是 output 的运行时输出
    auto softmax_output = output;
    
    // 计算 grad_output * softmax_output
    auto elementwise_prod = builder.mul(grad_output, softmax_output);
    
    // 沿最后一个轴求和
    int axis = softmax_output->output_shapes()[0].rank() - 1;
    auto sum_term = builder.sum(elementwise_prod, {axis}, true);  // keepdims=True
    
    // grad_output - sum_term
    auto diff = builder.sub(grad_output, sum_term);
    
    // 最终梯度
    auto grad_input = builder.mul(softmax_output, diff);
    
    return {grad_input};
}

std::vector<NodePtr> Conv2DGradient::compute_gradient(
    NodePtr output,
    NodePtr grad_output,
    const std::vector<NodePtr>& inputs
) {
    assert(inputs.size() >= 2);  // input, weight, [bias]
    
    auto input = inputs[0];
    auto weight = inputs[1];
    
    // 从操作符属性中获取卷积参数
    auto conv_op = dynamic_cast<const ops::Conv2DOperator*>(output->op());
    auto strides = conv_op->get_strides();
    auto padding = conv_op->get_padding();
    
    std::vector<NodePtr> grad_inputs;
    
    // 输入梯度：转置卷积
    auto grad_input = compute_input_gradient(grad_output, weight, strides, padding);
    grad_inputs.push_back(grad_input);
    
    // 权重梯度
    auto grad_weight = compute_weight_gradient(input, grad_output, 
                                              weight->output_shapes()[0],
                                              strides, padding);
    grad_inputs.push_back(grad_weight);
    
    // 偏置梯度（如果有）
    if (inputs.size() > 2) {
        // 偏置梯度：对输出梯度在batch、height、width维度求和
        GraphBuilder builder;
        auto grad_bias = builder.sum(grad_output, {0, 2, 3});  // 保留channel维度
        grad_inputs.push_back(grad_bias);
    }
    
    return grad_inputs;
}

// 注册所有基础梯度计算器
void register_basic_gradients() {
    auto& registry = GradientRegistry::instance();
    
    registry.register_gradient("Add", std::make_unique<AddGradient>());
    registry.register_gradient("Mul", std::make_unique<MulGradient>());
    registry.register_gradient("MatMul", std::make_unique<MatMulGradient>());
    registry.register_gradient("ReLU", std::make_unique<ReLUGradient>());
    registry.register_gradient("Softmax", std::make_unique<SoftmaxGradient>());
    registry.register_gradient("CrossEntropy", std::make_unique<CrossEntropyGradient>());
    registry.register_gradient("Conv2D", std::make_unique<Conv2DGradient>());
}

} // namespace autodiff
} // namespace minitvm
```

---

## Day 25-26: 自动调度与搜索

### 调度基础框架

```cpp
// include/minitvm/autoschedule/schedule_base.h
#pragma once

#include "minitvm/ir/tensor_ir.h"
#include "minitvm/core/target.h"
#include <memory>
#include <vector>

namespace minitvm {
namespace autoschedule {

// 调度变换
enum class ScheduleTransform {
    SPLIT,          // 循环拆分
    FUSE,           // 循环融合
    REORDER,        // 循环重排序
    PARALLEL,       // 并行化
    VECTORIZE,      // 向量化
    UNROLL,         // 循环展开
    TILE,           // 分块
    BIND,           // 绑定到线程
    CACHE_READ,     // 读缓存
    CACHE_WRITE,    // 写缓存
    COMPUTE_AT,     // 计算位置
    COMPUTE_INLINE, // 内联计算
    COMPUTE_ROOT    // 根计算
};

// 调度参数
struct ScheduleParam {
    ScheduleTransform transform;
    std::vector<int> int_params;
    std::vector<std::string> string_params;
    
    // 便利构造函数
    static ScheduleParam split(int factor);
    static ScheduleParam tile(const std::vector<int>& factors);
    static ScheduleParam parallel();
    static ScheduleParam vectorize(int factor = 4);
    static ScheduleParam unroll(int factor);
};

// 调度配置
class ScheduleConfig {
public:
    ScheduleConfig() = default;
    
    // 添加调度变换
    void add_transform(const std::string& loop_name, const ScheduleParam& param);
    void add_compute_at(const std::string& stage_name, const std::string& target_loop);
    
    // 获取调度参数
    const std::vector<std::pair<std::string, ScheduleParam>>& get_transforms() const {
        return transforms_;
    }
    
    // 序列化
    std::string to_json() const;
    static ScheduleConfig from_json(const std::string& json);
    
    // 调度质量评估
    struct Quality {
        double performance_score = 0.0;
        double memory_efficiency = 0.0;
        double parallelism_score = 0.0;
        double overall_score = 0.0;
    };
    
    Quality evaluate_quality(const codegen::Target& target) const;
    
private:
    std::vector<std::pair<std::string, ScheduleParam>> transforms_;
    std::unordered_map<std::string, std::string> compute_at_map_;
};

// 调度应用器 - 将调度配置应用到TensorIR
class ScheduleApplier {
public:
    explicit ScheduleApplier(const codegen::Target& target);
    
    // 应用调度
    ir::TensorIRFunction apply_schedule(const ir::TensorIRFunction& func,
                                       const ScheduleConfig& config);
    
    // 验证调度的合法性
    bool validate_schedule(const ir::TensorIRFunction& func,
                          const ScheduleConfig& config);
    
private:
    codegen::Target target_;
    
    // 具体变换实现
    ir::StmtPtr apply_split(ir::StmtPtr stmt, const std::string& loop_name, int factor);
    ir::StmtPtr apply_fuse(ir::StmtPtr stmt, const std::vector<std::string>& loop_names);
    ir::StmtPtr apply_reorder(ir::StmtPtr stmt, const std::vector<std::string>& loop_order);
    ir::StmtPtr apply_parallel(ir::StmtPtr stmt, const std::string& loop_name);
    ir::StmtPtr apply_vectorize(ir::StmtPtr stmt, const std::string& loop_name, int factor);
    ir::StmtPtr apply_unroll(ir::StmtPtr stmt, const std::string& loop_name, int factor);
    ir::StmtPtr apply_tile(ir::StmtPtr stmt, const std::string& loop_name,
                          const std::vector<int>& factors);
    
    // 辅助函数
    ir::For* find_loop(ir::StmtPtr stmt, const std::string& loop_name);
    std::vector<ir::For*> find_loops(ir::StmtPtr stmt, const std::vector<std::string>& loop_names);
};

// 搜索空间定义
class SearchSpace {
public:
    SearchSpace() = default;
    
    // 定义搜索维度
    void add_split_dimension(const std::string& loop_name, const std::vector<int>& factors);
    void add_tile_dimension(const std::string& loop_name, const std::vector<std::vector<int>>& tile_sizes);
    void add_boolean_dimension(const std::string& name, ScheduleTransform transform);
    
    // 搜索空间大小
    size_t size() const;
    
    // 采样随机配置
    ScheduleConfig sample_random_config() const;
    
    // 枚举所有配置（小搜索空间）
    std::vector<ScheduleConfig> enumerate_all_configs() const;
    
    // 生成邻域配置
    std::vector<ScheduleConfig> generate_neighbors(const ScheduleConfig& config) const;
    
private:
    struct Dimension {
        std::string name;
        ScheduleTransform transform;
        std::vector<std::string> string_choices;
        std::vector<int> int_choices;
        std::vector<std::vector<int>> vector_choices;
    };
    
    std::vector<Dimension> dimensions_;
};

} // namespace autoschedule
} // namespace minitvm
```

### 搜索算法实现

```cpp
// include/minitvm/autoschedule/search_algorithms.h
#pragma once

#include "schedule_base.h"
#include "minitvm/runtime/runtime_base.h"
#include <random>
#include <chrono>

namespace minitvm {
namespace autoschedule {

// 性能测量器
class PerformanceMeasurer {
public:
    explicit PerformanceMeasurer(const codegen::Target& target);
    
    // 测量单个配置的性能
    double measure_performance(const ir::TensorIRFunction& func,
                              const ScheduleConfig& config,
                              const std::vector<std::vector<Tensor>>& test_inputs,
                              int num_repeats = 10);
    
    // 批量测量
    std::vector<double> measure_batch(const ir::TensorIRFunction& func,
                                     const std::vector<ScheduleConfig>& configs,
                                     const std::vector<std::vector<Tensor>>& test_inputs);
    
    // 预估性能（基于模型）
    double estimate_performance(const ScheduleConfig& config);
    
private:
    codegen::Target target_;
    std::unique_ptr<jit::JITEngine> jit_engine_;
    
    // 统计时间
    double measure_execution_time(runtime::ModulePtr module,
                                 const std::string& func_name,
                                 const std::vector<Tensor>& inputs,
                                 int num_repeats);
};

// 搜索算法基类
class SearchAlgorithm {
public:
    virtual ~SearchAlgorithm() = default;
    
    // 搜索最优调度
    virtual ScheduleConfig search(const ir::TensorIRFunction& func,
                                 const SearchSpace& space,
                                 const std::vector<std::vector<Tensor>>& test_inputs,
                                 int max_iterations = 1000) = 0;
    
    // 搜索统计
    struct SearchStats {
        int total_iterations = 0;
        int valid_configs = 0;
        double best_performance = 0.0;
        ScheduleConfig best_config;
        std::vector<double> performance_history;
        double search_time_ms = 0.0;
    };
    
    const SearchStats& get_stats() const { return stats_; }
    
protected:
    SearchStats stats_;
    std::unique_ptr<PerformanceMeasurer> measurer_;
};

// 随机搜索
class RandomSearch : public SearchAlgorithm {
public:
    explicit RandomSearch(const codegen::Target& target, int seed = 42);
    
    ScheduleConfig search(const ir::TensorIRFunction& func,
                         const SearchSpace& space,
                         const std::vector<std::vector<Tensor>>& test_inputs,
                         int max_iterations = 1000) override;
    
private:
    std::mt19937 rng_;
};

// 网格搜索
class GridSearch : public SearchAlgorithm {
public:
    explicit GridSearch(const codegen::Target& target);
    
    ScheduleConfig search(const ir::TensorIRFunction& func,
                         const SearchSpace& space,
                         const std::vector<std::vector<Tensor>>& test_inputs,
                         int max_iterations = 1000) override;
};

// 模拟退火
class SimulatedAnnealing : public SearchAlgorithm {
public:
    struct SAParams {
        double initial_temperature = 100.0;
        double cooling_rate = 0.95;
        double min_temperature = 0.01;
        int iterations_per_temp = 100;
    };
    
    explicit SimulatedAnnealing(const codegen::Target& target, const SAParams& params = {});
    
    ScheduleConfig search(const ir::TensorIRFunction& func,
                         const SearchSpace& space,
                         const std::vector<std::vector<Tensor>>& test_inputs,
                         int max_iterations = 1000) override;
    
private:
    SAParams params_;
    std::mt19937 rng_;
    
    bool accept_config(double current_score, double new_score, double temperature);
};

// 遗传算法
class GeneticAlgorithm : public SearchAlgorithm {
public:
    struct GAParams {
        int population_size = 50;
        double mutation_rate = 0.1;
        double crossover_rate = 0.8;
        int elite_size = 5;
        int tournament_size = 3;
    };
    
    explicit GeneticAlgorithm(const codegen::Target& target, const GAParams& params = {});
    
    ScheduleConfig search(const ir::TensorIRFunction& func,
                         const SearchSpace& space,
                         const std::vector<std::vector<Tensor>>& test_inputs,
                         int max_iterations = 1000) override;
    
private:
    GAParams params_;
    std::mt19937 rng_;
    
    // 遗传算法操作
    std::vector<ScheduleConfig> initialize_population(const SearchSpace& space);
    std::vector<ScheduleConfig> selection(const std::vector<ScheduleConfig>& population,
                                         const std::vector<double>& fitness);
    ScheduleConfig crossover(const ScheduleConfig& parent1, const ScheduleConfig& parent2);
    ScheduleConfig mutate(const ScheduleConfig& config, const SearchSpace& space);
    
    int tournament_select(const std::vector<double>& fitness);
};

// 贝叶斯优化（基于高斯过程）
class BayesianOptimization : public SearchAlgorithm {
public:
    struct BOParams {
        int initial_random_samples = 20;
        double exploration_weight = 0.1;  // UCB参数
        std::string acquisition_function = "UCB";  // "UCB", "EI", "PI"
    };
    
    explicit BayesianOptimization(const codegen::Target& target, const BOParams& params = {});
    
    ScheduleConfig search(const ir::TensorIRFunction& func,
                         const SearchSpace& space,
                         const std::vector<std::vector<Tensor>>& test_inputs,
                         int max_iterations = 1000) override;
    
private:
    BOParams params_;
    
    // 高斯过程代理模型
    class GaussianProcess;
    std::unique_ptr<GaussianProcess> gp_model_;
    
    // 采集函数
    double upper_confidence_bound(const ScheduleConfig& config, double exploration_weight);
    double expected_improvement(const ScheduleConfig& config);
    double probability_of_improvement(const ScheduleConfig& config);
    
    // 配置向量化
    std::vector<double> config_to_vector(const ScheduleConfig& config);
    ScheduleConfig vector_to_config(const std::vector<double>& vector, const SearchSpace& space);
};

// 自动调度器 - 整合搜索算法
class AutoScheduler {
public:
    enum class Algorithm {
        RANDOM,
        GRID,
        SIMULATED_ANNEALING,
        GENETIC,
        BAYESIAN
    };
    
    explicit AutoScheduler(const codegen::Target& target);
    
    // 设置搜索算法
    void set_algorithm(Algorithm algo);
    void set_custom_algorithm(std::unique_ptr<SearchAlgorithm> algo);
    
    // 自动调度
    ScheduleConfig auto_schedule(const ir::TensorIRFunction& func,
                                const std::vector<std::vector<Tensor>>& test_inputs,
                                int max_time_minutes = 30);
    
    // 分析函数并生成搜索空间
    SearchSpace analyze_and_create_search_space(const ir::TensorIRFunction& func);
    
    // 调度建议
    std::vector<ScheduleConfig> suggest_schedules(const ir::TensorIRFunction& func,
                                                 int num_suggestions = 5);
    
private:
    codegen::Target target_;
    std::unique_ptr<SearchAlgorithm> current_algorithm_;
    
    // 分析循环嵌套
    struct LoopNest {
        std::string name;
        int extent;
        std::vector<LoopNest> children;
    };
    
    LoopNest analyze_loop_structure(const ir::TensorIRFunction& func);
    
    // 生成搜索空间的启发式规则
    void add_split_choices(SearchSpace& space, const LoopNest& loop);
    void add_tiling_choices(SearchSpace& space, const std::vector<LoopNest>& loops);
    void add_parallelization_choices(SearchSpace& space, const LoopNest& loop);
};

} // namespace autoschedule
} // namespace minitvm
```

---

## Day 27: 混合精度与量化

### 混合精度计算框架

```cpp
// include/minitvm/precision/mixed_precision.h
#pragma once

#include "minitvm/core/tensor.h"
#include "minitvm/core/graph.h"
#include <unordered_set>

namespace minitvm {
namespace precision {

// 精度策略
enum class PrecisionPolicy {
    FP32_ONLY,      // 仅使用FP32
    MIXED_FP16,     // 混合FP16/FP32
    INT8_QUANTIZED, // INT8量化
    DYNAMIC_MIXED,  // 动态混合精度
    AUTO_MIXED      // 自动混合精度
};

// 精度配置
class PrecisionConfig {
public:
    PrecisionConfig(PrecisionPolicy policy = PrecisionPolicy::FP32_ONLY);
    
    // 设置全局策略
    void set_policy(PrecisionPolicy policy) { policy_ = policy; }
    PrecisionPolicy get_policy() const { return policy_; }
    
    // 精度提示
    void set_node_precision(NodePtr node, DataType dtype);
    void set_operation_precision(const std::string& op_type, DataType dtype);
    
    // 损失缩放（用于FP16训练）
    void set_loss_scaling(double scale) { loss_scale_ = scale; }
    double get_loss_scaling() const { return loss_scale_; }
    void enable_dynamic_loss_scaling(bool enable) { dynamic_loss_scaling_ = enable; }
    bool is_dynamic_loss_scaling() const { return dynamic_loss_scaling_; }
    
    // 获取推荐精度
    DataType get_recommended_precision(NodePtr node) const;
    DataType get_recommended_precision(const std::string& op_type) const;
    
    // 白名单/黑名单
    void add_fp16_whitelist_op(const std::string& op_type);
    void add_fp16_blacklist_op(const std::string& op_type);
    bool is_fp16_safe(const std::string& op_type) const;
    
private:
    PrecisionPolicy policy_;
    double loss_scale_ = 65536.0;
    bool dynamic_loss_scaling_ = true;
    
    std::unordered_map<NodePtr, DataType> node_precision_hints_;
    std::unordered_map<std::string, DataType> op_precision_hints_;
    
    std::unordered_set<std::string> fp16_whitelist_;
    std::unordered_set<std::string> fp16_blacklist_;
    
    void initialize_default_precision_rules();
};

// 混合精度转换器
class MixedPrecisionConverter {
public:
    explicit MixedPrecisionConverter(const PrecisionConfig& config);
    
    // 转换计算图
    GraphPtr convert_graph(GraphPtr graph);
    
    // 插入类型转换节点
    NodePtr insert_cast_if_needed(NodePtr node, DataType target_dtype);
    
    // 分析精度传播
    void analyze_precision_propagation(GraphPtr graph);
    
private:
    PrecisionConfig config_;
    
    // 精度推导规则
    DataType infer_output_precision(NodePtr node);
    bool needs_type_conversion(NodePtr from_node, NodePtr to_node);
    
    // 特殊处理的操作
    void handle_loss_computation(NodePtr loss_node);
    void handle_gradient_computation(NodePtr grad_node);
    void handle_normalization_ops(NodePtr norm_node);
    
    // 类型转换优化
    void optimize_cast_operations(GraphPtr graph);
    void fuse_consecutive_casts(GraphPtr graph);
};

// 自动混合精度（AMP）
class AutoMixedPrecision {
public:
    struct AMPConfig {
        DataType default_dtype = DataType::FLOAT16;
        double loss_scale = 65536.0;
        bool dynamic_loss_scaling = true;
        int loss_scale_window = 2000;
        double growth_factor = 2.0;
        double backoff_factor = 0.5;
        
        // 数值稳定性阈值
        double gradient_clip_threshold = 1.0;
        double inf_nan_skip_threshold = 1000.0;
    };
    
    explicit AutoMixedPrecision(const AMPConfig& config = {});
    
    // 包装模型以支持AMP
    GraphPtr wrap_model(GraphPtr model);
    
    // 损失缩放
    class LossScaler {
    public:
        explicit LossScaler(double initial_scale = 65536.0, bool dynamic = true);
        
        Tensor scale_loss(const Tensor& loss);
        std::vector<Tensor> unscale_gradients(const std::vector<Tensor>& gradients);
        
        void update_scale(bool found_inf);
        double get_current_scale() const { return current_scale_; }
        
    private:
        double current_scale_;
        bool dynamic_scaling_;
        int growth_interval_;
        int num_good_steps_;
        double growth_factor_;
        double backoff_factor_;
    };
    
    LossScaler& get_loss_scaler() { return loss_scaler_; }
    
    // 梯度检查
    bool check_gradients_finite(const std::vector<Tensor>& gradients);
    
private:
    AMPConfig config_;
    LossScaler loss_scaler_;
    
    // 插入AMP相关节点
    void insert_loss_scaling_nodes(GraphPtr graph);
    void insert_gradient_unscaling_nodes(GraphPtr graph);
    void insert_gradient_clipping_nodes(GraphPtr graph);
};

// 量化支持
class Quantization {
public:
    enum class QuantizationMode {
        POST_TRAINING,   // 训练后量化
        QUANTIZATION_AWARE_TRAINING,  // 量化感知训练
        DYNAMIC_QUANTIZATION  // 动态量化
    };
    
    struct QuantizationConfig {
        QuantizationMode mode = QuantizationMode::POST_TRAINING;
        DataType target_dtype = DataType::INT8;
        bool per_channel = true;
        bool symmetric = false;
        double calibration_ratio = 0.1;  // 校准数据比例
    };
    
    explicit Quantization(const QuantizationConfig& config);
    
    // 训练后量化
    GraphPtr post_training_quantize(GraphPtr model, 
                                   const std::vector<std::vector<Tensor>>& calibration_data);
    
    // 量化感知训练
    GraphPtr quantization_aware_training_prepare(GraphPtr model);
    
    // 校准和量化参数计算
    struct QuantizationParams {
        double scale;
        int zero_point;
        double min_val;
        double max_val;
    };
    
    QuantizationParams calibrate_tensor(const Tensor& tensor);
    
    // 量化/反量化操作
    Tensor quantize_tensor(const Tensor& tensor, const QuantizationParams& params);
    Tensor dequantize_tensor(const Tensor& quantized_tensor, const QuantizationParams& params);
    
private:
    QuantizationConfig config_;
    
    // 支持量化的操作类型
    std::unordered_set<std::string> quantizable_ops_;
    
    // 量化节点插入
    void insert_quantization_nodes(GraphPtr graph);
    void insert_dequantization_nodes(GraphPtr graph);
    
    // 统计信息收集
    std::unordered_map<NodePtr, QuantizationParams> collect_activation_stats(
        GraphPtr model, const std::vector<std::vector<Tensor>>& calibration_data);
};

} // namespace precision
} // namespace minitvm
```

### 实现示例

```cpp
// src/precision/mixed_precision.cpp
#include "minitvm/precision/mixed_precision.h"

namespace minitvm {
namespace precision {

PrecisionConfig::PrecisionConfig(PrecisionPolicy policy) : policy_(policy) {
    initialize_default_precision_rules();
}

void PrecisionConfig::initialize_default_precision_rules() {
    // FP16 安全操作（通常不会导致数值不稳定）
    fp16_whitelist_.insert({
        "Add", "Sub", "Mul", "Div",
        "ReLU", "GELU", "Tanh",
        "Conv2D", "MatMul", "BatchNorm"
    });
    
    // FP16 不安全操作（可能导致数值不稳定）
    fp16_blacklist_.insert({
        "Exp", "Log", "Pow", "Sqrt",
        "Softmax", "LayerNorm", "Loss",
        "Sum", "Mean"  // 归约操作容易导致下溢
    });
}

DataType PrecisionConfig::get_recommended_precision(NodePtr node) const {
    // 检查节点特定的精度提示
    auto it = node_precision_hints_.find(node);
    if (it != node_precision_hints_.end()) {
        return it->second;
    }
    
    // 检查操作类型的精度提示
    if (node->has_operator()) {
        auto op_it = op_precision_hints_.find(node->op()->type());
        if (op_it != op_precision_hints_.end()) {
            return op_it->second;
        }
    }
    
    // 根据策略决定
    switch (policy_) {
        case PrecisionPolicy::FP32_ONLY:
            return DataType::FLOAT32;
            
        case PrecisionPolicy::MIXED_FP16:
            if (node->has_operator() && is_fp16_safe(node->op()->type())) {
                return DataType::FLOAT16;
            }
            return DataType::FLOAT32;
            
        case PrecisionPolicy::AUTO_MIXED:
            // 更复杂的启发式规则
            return infer_auto_precision(node);
            
        default:
            return DataType::FLOAT32;
    }
}

GraphPtr MixedPrecisionConverter::convert_graph(GraphPtr graph) {
    // 1. 分析精度传播
    analyze_precision_propagation(graph);
    
    // 2. 插入类型转换
    for (auto node : graph->nodes()) {
        DataType target_dtype = config_.get_recommended_precision(node);
        
        // 检查输入是否需要转换
        for (auto input : node->inputs()) {
            if (input->output_dtypes()[0] != target_dtype) {
                auto cast_node = insert_cast_if_needed(input, target_dtype);
                // 更新连接...
            }
        }
    }
    
    // 3. 优化类型转换
    optimize_cast_operations(graph);
    
    return graph;
}

// 自动混合精度实现
GraphPtr AutoMixedPrecision::wrap_model(GraphPtr model) {
    GraphBuilder builder;
    
    // 1. 转换前向计算为FP16
    PrecisionConfig fp16_config(PrecisionPolicy::MIXED_FP16);
    MixedPrecisionConverter converter(fp16_config);
    auto fp16_model = converter.convert_graph(model);
    
    // 2. 插入损失缩放
    insert_loss_scaling_nodes(fp16_model);
    
    // 3. 插入梯度处理
    insert_gradient_unscaling_nodes(fp16_model);
    insert_gradient_clipping_nodes(fp16_model);
    
    return fp16_model;
}

Tensor AutoMixedPrecision::LossScaler::scale_loss(const Tensor& loss) {
    if (!dynamic_scaling_) {
        return loss * current_scale_;
    }
    
    // 动态缩放：检查损失值范围
    auto loss_data = loss.data<float>();
    double max_val = *std::max_element(loss_data, loss_data + loss.numel());
    
    if (max_val * current_scale_ > 65504.0) {  // FP16最大值
        current_scale_ *= backoff_factor_;
    }
    
    return loss * current_scale_;
}

// 量化实现
Quantization::QuantizationParams Quantization::calibrate_tensor(const Tensor& tensor) {
    auto data = tensor.data<float>();
    size_t size = tensor.numel();
    
    // 计算最小最大值
    double min_val = *std::min_element(data, data + size);
    double max_val = *std::max_element(data, data + size);
    
    QuantizationParams params;
    params.min_val = min_val;
    params.max_val = max_val;
    
    if (config_.symmetric) {
        // 对称量化
        double abs_max = std::max(std::abs(min_val), std::abs(max_val));
        params.scale = (2 * abs_max) / 255.0;  // INT8范围
        params.zero_point = 0;
    } else {
        // 非对称量化
        params.scale = (max_val - min_val) / 255.0;
        params.zero_point = static_cast<int>(-min_val / params.scale);
    }
    
    return params;
}

Tensor Quantization::quantize_tensor(const Tensor& tensor, const QuantizationParams& params) {
    auto input_data = tensor.data<float>();
    auto quantized = zeros(tensor.shape(), DataType::INT8, tensor.device());
    auto output_data = quantized.data<int8_t>();
    
    for (size_t i = 0; i < tensor.numel(); ++i) {
        int quantized_val = static_cast<int>(input_data[i] / params.scale + params.zero_point);
        quantized_val = std::clamp(quantized_val, -128, 127);
        output_data[i] = static_cast<int8_t>(quantized_val);
    }
    
    return quantized;
}

} // namespace precision
} // namespace minitvm
```

---

## 第五阶段总结

### 已完成的功能

1. **自动微分系统**
   - 前向模式和反向模式自动微分
   - 梯度计算器注册机制
   - 基础操作的梯度实现
   - 高阶导数支持

2. **自动调度与搜索**
   - 调度变换定义和应用
   - 多种搜索算法（随机、网格、模拟退火、遗传、贝叶斯优化）
   - 性能测量和评估
   - 搜索空间自动生成

3. **混合精度与量化**
   - 混合精度策略
   - 自动混合精度（AMP）
   - 损失缩放和梯度处理
   - 训练后量化和量化感知训练

### 学习要点

1. **高级算法**
   - 自动微分的实现原理
   - 启发式搜索算法
   - 数值优化方法

2. **系统优化**
   - 性能调优策略
   - 内存和计算优化
   - 数值稳定性考虑

3. **工程复杂性**
   - 大型系统的模块化设计
   - 复杂算法的工程实现
   - 性能与精度的权衡

这些高级特性使 MiniTVM 具备了现代深度学习编译器的核心能力，为处理实际的深度学习模型提供了必要的工具和优化手段。
