# 第一阶段：基础框架实现详解

## 概述

在第一阶段，我们将建立 MiniTVM 的核心基础设施，包括基本数据结构、操作符抽象和计算图表示。这是整个编译器的基石。

## 实现计划

### Day 1-3: 核心数据结构
### Day 4-6: 基础操作符系统  
### Day 7-10: 计算图实现

---

## Day 1-3: 核心数据结构实现

### 项目初始化

#### CMakeLists.txt 配置

```cmake
cmake_minimum_required(VERSION 3.15)
project(MiniTVM VERSION 1.0.0)

set(CMAKE_CXX_STANDARD 17)
set(CMAKE_CXX_STANDARD_REQUIRED ON)

# 编译选项
set(CMAKE_CXX_FLAGS_DEBUG "-g -O0 -Wall -Wextra")
set(CMAKE_CXX_FLAGS_RELEASE "-O3 -DNDEBUG")

# 查找依赖
find_package(LLVM REQUIRED CONFIG)
find_package(CUDA QUIET)

# 包含目录
include_directories(${CMAKE_CURRENT_SOURCE_DIR}/include)
include_directories(${LLVM_INCLUDE_DIRS})

# 源文件
file(GLOB_RECURSE SOURCES "src/*.cpp")
file(GLOB_RECURSE HEADERS "include/*.h")

# 创建库
add_library(minitvm ${SOURCES} ${HEADERS})

# 链接库
target_link_libraries(minitvm ${LLVM_LIBS})

if(CUDA_FOUND)
    enable_language(CUDA)
    target_link_libraries(minitvm ${CUDA_LIBRARIES})
    target_compile_definitions(minitvm PRIVATE MINITVM_CUDA_SUPPORT)
endif()

# 测试
enable_testing()
find_package(GTest REQUIRED)
add_subdirectory(tests)

# 示例
add_subdirectory(examples)
```

### 完整的 Tensor 实现

```cpp
// include/minitvm/core/tensor.h
#pragma once

#include <vector>
#include <memory>
#include <string>
#include <cassert>
#include <numeric>

namespace minitvm {

enum class DataType {
    FLOAT32 = 0,
    FLOAT64 = 1,
    INT32 = 2,
    INT64 = 3,
    BOOL = 4,
    UINT8 = 5,
    INT8 = 6,
};

enum class DeviceType {
    CPU = 0,
    CUDA = 1,
    OPENCL = 2,
    VULKAN = 3,
};

// 数据类型工具函数
size_t get_dtype_size(DataType dtype);
std::string dtype_to_string(DataType dtype);
std::string device_to_string(DeviceType device);

class Shape {
public:
    Shape() = default;
    Shape(const std::vector<int64_t>& dims) : dims_(dims) {}
    Shape(std::initializer_list<int64_t> dims) : dims_(dims) {}
    
    // 访问接口
    const std::vector<int64_t>& dims() const { return dims_; }
    int64_t operator[](size_t idx) const { return dims_[idx]; }
    size_t rank() const { return dims_.size(); }
    bool empty() const { return dims_.empty(); }
    
    // 计算接口
    int64_t size() const {
        return std::accumulate(dims_.begin(), dims_.end(), 1LL, std::multiplies<int64_t>());
    }
    
    // 形状操作
    Shape slice(size_t start, size_t end) const;
    Shape concat(const Shape& other) const;
    Shape broadcast_with(const Shape& other) const;
    bool is_broadcastable_with(const Shape& other) const;
    
    // 比较操作
    bool operator==(const Shape& other) const { return dims_ == other.dims_; }
    bool operator!=(const Shape& other) const { return !(*this == other); }
    
    // 字符串表示
    std::string to_string() const;

private:
    std::vector<int64_t> dims_;
};

// 前置声明
class Device;
class Storage;

class Tensor {
public:
    // 构造函数
    Tensor() = default;
    Tensor(const Shape& shape, DataType dtype, DeviceType device = DeviceType::CPU);
    Tensor(const Shape& shape, DataType dtype, std::shared_ptr<Storage> storage);
    
    // 拷贝和移动
    Tensor(const Tensor& other) = default;
    Tensor& operator=(const Tensor& other) = default;
    Tensor(Tensor&& other) noexcept = default;
    Tensor& operator=(Tensor&& other) noexcept = default;
    
    // 基本属性
    const Shape& shape() const { return shape_; }
    DataType dtype() const { return dtype_; }
    DeviceType device() const;
    bool is_valid() const { return storage_ != nullptr; }
    
    // 数据访问
    void* data() const;
    template<typename T> T* data() const { return static_cast<T*>(data()); }
    size_t size_bytes() const;
    size_t numel() const { return shape_.size(); }
    
    // 形状操作
    Tensor reshape(const Shape& new_shape) const;
    Tensor view(const Shape& new_shape) const;
    Tensor transpose(const std::vector<int>& axes = {}) const;
    Tensor squeeze(int dim = -1) const;
    Tensor unsqueeze(int dim) const;
    
    // 设备操作
    Tensor to_device(DeviceType device) const;
    Tensor cpu() const { return to_device(DeviceType::CPU); }
    Tensor cuda() const { return to_device(DeviceType::CUDA); }
    
    // 类型转换
    Tensor to_dtype(DataType dtype) const;
    
    // 切片和索引
    Tensor slice(const std::vector<std::pair<int64_t, int64_t>>& ranges) const;
    Tensor index(const std::vector<int64_t>& indices) const;
    
    // 调试和可视化
    std::string to_string() const;
    void print() const;
    
    // 底层存储访问
    std::shared_ptr<Storage> storage() const { return storage_; }

private:
    Shape shape_;
    DataType dtype_ = DataType::FLOAT32;
    std::shared_ptr<Storage> storage_;
    int64_t offset_ = 0;
    std::vector<int64_t> strides_;
    
    void compute_strides();
    bool is_contiguous() const;
};

// Storage 抽象 - 管理实际的内存
class Storage {
public:
    virtual ~Storage() = default;
    
    virtual void* data() const = 0;
    virtual size_t size_bytes() const = 0;
    virtual DeviceType device() const = 0;
    virtual std::shared_ptr<Storage> copy() const = 0;
    virtual std::shared_ptr<Storage> to_device(DeviceType device) const = 0;
};

// CPU 存储实现
class CPUStorage : public Storage {
public:
    explicit CPUStorage(size_t size_bytes);
    ~CPUStorage() override;
    
    void* data() const override { return data_; }
    size_t size_bytes() const override { return size_bytes_; }
    DeviceType device() const override { return DeviceType::CPU; }
    std::shared_ptr<Storage> copy() const override;
    std::shared_ptr<Storage> to_device(DeviceType device) const override;

private:
    void* data_;
    size_t size_bytes_;
};

#ifdef MINITVM_CUDA_SUPPORT
// CUDA 存储实现
class CUDAStorage : public Storage {
public:
    explicit CUDAStorage(size_t size_bytes);
    ~CUDAStorage() override;
    
    void* data() const override { return data_; }
    size_t size_bytes() const override { return size_bytes_; }
    DeviceType device() const override { return DeviceType::CUDA; }
    std::shared_ptr<Storage> copy() const override;
    std::shared_ptr<Storage> to_device(DeviceType device) const override;

private:
    void* data_;
    size_t size_bytes_;
};
#endif

// 工厂函数
std::shared_ptr<Storage> create_storage(size_t size_bytes, DeviceType device);

// 张量创建函数
Tensor zeros(const Shape& shape, DataType dtype = DataType::FLOAT32, DeviceType device = DeviceType::CPU);
Tensor ones(const Shape& shape, DataType dtype = DataType::FLOAT32, DeviceType device = DeviceType::CPU);
Tensor full(const Shape& shape, double value, DataType dtype = DataType::FLOAT32, DeviceType device = DeviceType::CPU);
Tensor arange(int64_t start, int64_t end, int64_t step = 1, DataType dtype = DataType::INT64, DeviceType device = DeviceType::CPU);
Tensor randn(const Shape& shape, DataType dtype = DataType::FLOAT32, DeviceType device = DeviceType::CPU);

} // namespace minitvm
```

### Tensor 实现文件

```cpp
// src/core/tensor.cpp
#include "minitvm/core/tensor.h"
#include <iostream>
#include <sstream>
#include <random>
#include <cstring>

#ifdef MINITVM_CUDA_SUPPORT
#include <cuda_runtime.h>
#endif

namespace minitvm {

// 数据类型工具函数实现
size_t get_dtype_size(DataType dtype) {
    switch (dtype) {
        case DataType::FLOAT32: return 4;
        case DataType::FLOAT64: return 8;
        case DataType::INT32: return 4;
        case DataType::INT64: return 8;
        case DataType::BOOL: return 1;
        case DataType::UINT8: return 1;
        case DataType::INT8: return 1;
        default: return 0;
    }
}

std::string dtype_to_string(DataType dtype) {
    switch (dtype) {
        case DataType::FLOAT32: return "float32";
        case DataType::FLOAT64: return "float64";
        case DataType::INT32: return "int32";
        case DataType::INT64: return "int64";
        case DataType::BOOL: return "bool";
        case DataType::UINT8: return "uint8";
        case DataType::INT8: return "int8";
        default: return "unknown";
    }
}

std::string device_to_string(DeviceType device) {
    switch (device) {
        case DeviceType::CPU: return "cpu";
        case DeviceType::CUDA: return "cuda";
        case DeviceType::OPENCL: return "opencl";
        case DeviceType::VULKAN: return "vulkan";
        default: return "unknown";
    }
}

// Shape 实现
Shape Shape::slice(size_t start, size_t end) const {
    assert(start <= end && end <= dims_.size());
    return Shape(std::vector<int64_t>(dims_.begin() + start, dims_.begin() + end));
}

Shape Shape::concat(const Shape& other) const {
    std::vector<int64_t> result = dims_;
    result.insert(result.end(), other.dims_.begin(), other.dims_.end());
    return Shape(result);
}

bool Shape::is_broadcastable_with(const Shape& other) const {
    // 实现广播规则
    int i = static_cast<int>(dims_.size()) - 1;
    int j = static_cast<int>(other.dims_.size()) - 1;
    
    while (i >= 0 || j >= 0) {
        int64_t dim1 = (i >= 0) ? dims_[i] : 1;
        int64_t dim2 = (j >= 0) ? other.dims_[j] : 1;
        
        if (dim1 != dim2 && dim1 != 1 && dim2 != 1) {
            return false;
        }
        
        i--;
        j--;
    }
    
    return true;
}

Shape Shape::broadcast_with(const Shape& other) const {
    assert(is_broadcastable_with(other));
    
    size_t max_rank = std::max(dims_.size(), other.dims_.size());
    std::vector<int64_t> result(max_rank);
    
    for (size_t i = 0; i < max_rank; ++i) {
        int64_t dim1 = (i < dims_.size()) ? dims_[dims_.size() - 1 - i] : 1;
        int64_t dim2 = (i < other.dims_.size()) ? other.dims_[other.dims_.size() - 1 - i] : 1;
        
        result[max_rank - 1 - i] = std::max(dim1, dim2);
    }
    
    return Shape(result);
}

std::string Shape::to_string() const {
    std::ostringstream oss;
    oss << "(";
    for (size_t i = 0; i < dims_.size(); ++i) {
        if (i > 0) oss << ", ";
        oss << dims_[i];
    }
    oss << ")";
    return oss.str();
}

// CPUStorage 实现
CPUStorage::CPUStorage(size_t size_bytes) : size_bytes_(size_bytes) {
    data_ = std::aligned_alloc(64, size_bytes); // 64字节对齐
    if (!data_) {
        throw std::runtime_error("Failed to allocate CPU memory");
    }
}

CPUStorage::~CPUStorage() {
    if (data_) {
        std::free(data_);
    }
}

std::shared_ptr<Storage> CPUStorage::copy() const {
    auto new_storage = std::make_shared<CPUStorage>(size_bytes_);
    std::memcpy(new_storage->data(), data_, size_bytes_);
    return new_storage;
}

std::shared_ptr<Storage> CPUStorage::to_device(DeviceType device) const {
    if (device == DeviceType::CPU) {
        return copy();
    }
    
#ifdef MINITVM_CUDA_SUPPORT
    if (device == DeviceType::CUDA) {
        auto cuda_storage = std::make_shared<CUDAStorage>(size_bytes_);
        cudaMemcpy(cuda_storage->data(), data_, size_bytes_, cudaMemcpyHostToDevice);
        return cuda_storage;
    }
#endif
    
    throw std::runtime_error("Unsupported device type");
}

#ifdef MINITVM_CUDA_SUPPORT
// CUDAStorage 实现
CUDAStorage::CUDAStorage(size_t size_bytes) : size_bytes_(size_bytes) {
    auto result = cudaMalloc(&data_, size_bytes);
    if (result != cudaSuccess) {
        throw std::runtime_error("Failed to allocate CUDA memory");
    }
}

CUDAStorage::~CUDAStorage() {
    if (data_) {
        cudaFree(data_);
    }
}

std::shared_ptr<Storage> CUDAStorage::copy() const {
    auto new_storage = std::make_shared<CUDAStorage>(size_bytes_);
    cudaMemcpy(new_storage->data(), data_, size_bytes_, cudaMemcpyDeviceToDevice);
    return new_storage;
}

std::shared_ptr<Storage> CUDAStorage::to_device(DeviceType device) const {
    if (device == DeviceType::CUDA) {
        return copy();
    }
    
    if (device == DeviceType::CPU) {
        auto cpu_storage = std::make_shared<CPUStorage>(size_bytes_);
        cudaMemcpy(cpu_storage->data(), data_, size_bytes_, cudaMemcpyDeviceToHost);
        return cpu_storage;
    }
    
    throw std::runtime_error("Unsupported device type");
}
#endif

// 工厂函数
std::shared_ptr<Storage> create_storage(size_t size_bytes, DeviceType device) {
    switch (device) {
        case DeviceType::CPU:
            return std::make_shared<CPUStorage>(size_bytes);
#ifdef MINITVM_CUDA_SUPPORT
        case DeviceType::CUDA:
            return std::make_shared<CUDAStorage>(size_bytes);
#endif
        default:
            throw std::runtime_error("Unsupported device type");
    }
}

// Tensor 实现
Tensor::Tensor(const Shape& shape, DataType dtype, DeviceType device)
    : shape_(shape), dtype_(dtype) {
    size_t size_bytes = shape.size() * get_dtype_size(dtype);
    storage_ = create_storage(size_bytes, device);
    compute_strides();
}

Tensor::Tensor(const Shape& shape, DataType dtype, std::shared_ptr<Storage> storage)
    : shape_(shape), dtype_(dtype), storage_(storage) {
    compute_strides();
}

DeviceType Tensor::device() const {
    return storage_ ? storage_->device() : DeviceType::CPU;
}

void* Tensor::data() const {
    if (!storage_) return nullptr;
    return static_cast<char*>(storage_->data()) + offset_ * get_dtype_size(dtype_);
}

size_t Tensor::size_bytes() const {
    return numel() * get_dtype_size(dtype_);
}

void Tensor::compute_strides() {
    strides_.resize(shape_.rank());
    if (strides_.empty()) return;
    
    strides_.back() = 1;
    for (int i = static_cast<int>(strides_.size()) - 2; i >= 0; --i) {
        strides_[i] = strides_[i + 1] * shape_[i + 1];
    }
}

bool Tensor::is_contiguous() const {
    if (strides_.empty()) return true;
    
    int64_t expected_stride = 1;
    for (int i = static_cast<int>(strides_.size()) - 1; i >= 0; --i) {
        if (strides_[i] != expected_stride) {
            return false;
        }
        expected_stride *= shape_[i];
    }
    return true;
}

Tensor Tensor::reshape(const Shape& new_shape) const {
    assert(new_shape.size() == numel());
    
    if (is_contiguous()) {
        // 可以直接改变形状
        Tensor result = *this;
        result.shape_ = new_shape;
        result.compute_strides();
        return result;
    } else {
        // 需要拷贝数据
        Tensor result(new_shape, dtype_, device());
        // TODO: 实现数据拷贝
        return result;
    }
}

Tensor Tensor::to_device(DeviceType device) const {
    if (this->device() == device) {
        return *this;
    }
    
    auto new_storage = storage_->to_device(device);
    return Tensor(shape_, dtype_, new_storage);
}

std::string Tensor::to_string() const {
    std::ostringstream oss;
    oss << "Tensor(shape=" << shape_.to_string()
        << ", dtype=" << dtype_to_string(dtype_)
        << ", device=" << device_to_string(device()) << ")";
    return oss.str();
}

void Tensor::print() const {
    std::cout << to_string() << std::endl;
}

// 张量创建函数
Tensor zeros(const Shape& shape, DataType dtype, DeviceType device) {
    Tensor tensor(shape, dtype, device);
    
    // 初始化为0
    size_t size_bytes = tensor.size_bytes();
    if (device == DeviceType::CPU) {
        std::memset(tensor.data(), 0, size_bytes);
    }
#ifdef MINITVM_CUDA_SUPPORT
    else if (device == DeviceType::CUDA) {
        cudaMemset(tensor.data(), 0, size_bytes);
    }
#endif
    
    return tensor;
}

Tensor ones(const Shape& shape, DataType dtype, DeviceType device) {
    Tensor tensor(shape, dtype, device);
    
    // 初始化为1
    if (device == DeviceType::CPU) {
        if (dtype == DataType::FLOAT32) {
            float* data = tensor.data<float>();
            std::fill(data, data + tensor.numel(), 1.0f);
        } else if (dtype == DataType::INT32) {
            int32_t* data = tensor.data<int32_t>();
            std::fill(data, data + tensor.numel(), 1);
        }
        // 其他类型...
    }
    
    return tensor;
}

Tensor randn(const Shape& shape, DataType dtype, DeviceType device) {
    Tensor tensor(shape, dtype, device);
    
    if (device == DeviceType::CPU && dtype == DataType::FLOAT32) {
        std::random_device rd;
        std::mt19937 gen(rd());
        std::normal_distribution<float> dist(0.0f, 1.0f);
        
        float* data = tensor.data<float>();
        for (int64_t i = 0; i < tensor.numel(); ++i) {
            data[i] = dist(gen);
        }
    }
    
    return tensor;
}

} // namespace minitvm
```

### 测试代码

```cpp
// tests/unit/test_tensor.cpp
#include <gtest/gtest.h>
#include "minitvm/core/tensor.h"
#include <cmath>

using namespace minitvm;

class TensorTest : public ::testing::Test {
protected:
    void SetUp() override {}
    void TearDown() override {}
};

TEST_F(TensorTest, BasicConstruction) {
    Shape shape({2, 3, 4});
    Tensor tensor(shape, DataType::FLOAT32, DeviceType::CPU);
    
    EXPECT_EQ(tensor.shape(), shape);
    EXPECT_EQ(tensor.dtype(), DataType::FLOAT32);
    EXPECT_EQ(tensor.device(), DeviceType::CPU);
    EXPECT_EQ(tensor.numel(), 24);
    EXPECT_TRUE(tensor.is_valid());
}

TEST_F(TensorTest, ShapeOperations) {
    Shape shape1({2, 3});
    Shape shape2({3, 4});
    
    EXPECT_EQ(shape1.size(), 6);
    EXPECT_EQ(shape1.rank(), 2);
    EXPECT_EQ(shape1[0], 2);
    EXPECT_EQ(shape1[1], 3);
    
    Shape concat_shape = shape1.concat(shape2);
    EXPECT_EQ(concat_shape.dims(), std::vector<int64_t>({2, 3, 3, 4}));
}

TEST_F(TensorTest, Broadcasting) {
    Shape shape1({2, 1, 4});
    Shape shape2({3, 4});
    
    EXPECT_TRUE(shape1.is_broadcastable_with(shape2));
    Shape broadcast_shape = shape1.broadcast_with(shape2);
    EXPECT_EQ(broadcast_shape.dims(), std::vector<int64_t>({2, 3, 4}));
}

TEST_F(TensorTest, TensorCreation) {
    Shape shape({3, 4});
    
    auto zeros_tensor = zeros(shape, DataType::FLOAT32);
    EXPECT_EQ(zeros_tensor.shape(), shape);
    EXPECT_EQ(zeros_tensor.dtype(), DataType::FLOAT32);
    
    auto ones_tensor = ones(shape, DataType::FLOAT32);
    EXPECT_EQ(ones_tensor.shape(), shape);
    
    auto randn_tensor = randn(shape, DataType::FLOAT32);
    EXPECT_EQ(randn_tensor.shape(), shape);
}

TEST_F(TensorTest, Reshape) {
    auto tensor = zeros({2, 3, 4});
    auto reshaped = tensor.reshape({6, 4});
    
    EXPECT_EQ(reshaped.shape().dims(), std::vector<int64_t>({6, 4}));
    EXPECT_EQ(reshaped.numel(), tensor.numel());
}

#ifdef MINITVM_CUDA_SUPPORT
TEST_F(TensorTest, DeviceTransfer) {
    auto cpu_tensor = zeros({2, 3}, DataType::FLOAT32, DeviceType::CPU);
    auto cuda_tensor = cpu_tensor.cuda();
    
    EXPECT_EQ(cuda_tensor.device(), DeviceType::CUDA);
    EXPECT_EQ(cuda_tensor.shape(), cpu_tensor.shape());
    
    auto back_to_cpu = cuda_tensor.cpu();
    EXPECT_EQ(back_to_cpu.device(), DeviceType::CPU);
}
#endif

TEST_F(TensorTest, DataTypeSize) {
    EXPECT_EQ(get_dtype_size(DataType::FLOAT32), 4);
    EXPECT_EQ(get_dtype_size(DataType::FLOAT64), 8);
    EXPECT_EQ(get_dtype_size(DataType::INT32), 4);
    EXPECT_EQ(get_dtype_size(DataType::INT64), 8);
}

TEST_F(TensorTest, StringRepresentation) {
    Shape shape({2, 3});
    EXPECT_EQ(shape.to_string(), "(2, 3)");
    
    Tensor tensor(shape, DataType::FLOAT32);
    std::string tensor_str = tensor.to_string();
    EXPECT_TRUE(tensor_str.find("Tensor") != std::string::npos);
    EXPECT_TRUE(tensor_str.find("(2, 3)") != std::string::npos);
}
```

---

## 第一阶段总结

### 已完成的功能

1. **完整的张量系统**
   - 多维形状表示和操作
   - 多种数据类型支持
   - CPU/CUDA 设备抽象
   - 内存管理和存储抽象

2. **基础设施**
   - CMake 构建系统
   - 单元测试框架
   - 跨平台支持

3. **核心特性**
   - 张量创建和操作
   - 形状推导和广播
   - 设备间数据传输
   - 内存对齐和优化

### 学习要点

1. **设计模式应用**
   - 策略模式：不同设备的存储实现
   - 工厂模式：张量和存储的创建
   - RAII：自动内存管理

2. **性能考虑**
   - 内存对齐优化
   - 引用计数避免不必要拷贝
   - 延迟计算的设计准备

3. **错误处理**
   - 异常安全的内存管理
   - 参数验证和断言
   - 详细的错误信息

### 下一阶段预览

在下一阶段，我们将实现：
- 操作符抽象和注册系统
- 基础数学运算的实现
- 自动微分的基础设施
- 计算图的构建和遍历

这个基础框架为后续的复杂功能提供了坚实的基础。
