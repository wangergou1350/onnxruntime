# 第二阶段：操作符系统与计算图

## 概述

在第二阶段，我们将构建 MiniTVM 的操作符系统和计算图基础设施。这包括操作符的抽象接口、注册机制、基础数学运算实现，以及计算图的构建和管理。

## 实现计划

### Day 4-6: 操作符抽象系统
### Day 7-8: 基础数学运算  
### Day 9-10: 计算图实现

---

## Day 4-6: 操作符抽象系统

### 操作符基类设计

```cpp
// include/minitvm/core/operator.h
#pragma once

#include "tensor.h"
#include <vector>
#include <string>
#include <unordered_map>
#include <memory>
#include <functional>

namespace minitvm {

// 操作符属性类型
using AttrValue = std::variant<int64_t, double, std::string, bool, std::vector<int64_t>>;
using AttrMap = std::unordered_map<std::string, AttrValue>;

// 前置声明
class OpContext;

class Operator {
public:
    virtual ~Operator() = default;
    
    // 核心接口
    virtual std::string name() const = 0;
    virtual std::string type() const = 0;
    
    // 形状推导
    virtual std::vector<Shape> infer_shape(const std::vector<Shape>& input_shapes) const = 0;
    
    // 类型推导
    virtual std::vector<DataType> infer_dtype(const std::vector<DataType>& input_dtypes) const = 0;
    
    // 设备推导
    virtual DeviceType infer_device(const std::vector<DeviceType>& input_devices) const;
    
    // 计算接口
    virtual std::vector<Tensor> compute(const std::vector<Tensor>& inputs, 
                                       const OpContext& ctx) const = 0;
    
    // 梯度计算
    virtual std::vector<Tensor> gradient(const std::vector<Tensor>& inputs,
                                        const std::vector<Tensor>& grad_outputs,
                                        const OpContext& ctx) const;
    
    // 操作符优化
    virtual bool can_fuse_with(const Operator& other) const { return false; }
    virtual std::unique_ptr<Operator> fuse_with(const Operator& other) const;
    
    // 属性管理
    void set_attr(const std::string& key, const AttrValue& value);
    AttrValue get_attr(const std::string& key) const;
    bool has_attr(const std::string& key) const;
    const AttrMap& attrs() const { return attrs_; }
    
    // 验证
    virtual bool validate(const std::vector<Shape>& input_shapes,
                         const std::vector<DataType>& input_dtypes) const;
    
    // 调试信息
    virtual std::string to_string() const;
    
protected:
    AttrMap attrs_;
};

// 操作符上下文 - 包含计算所需的环境信息
class OpContext {
public:
    OpContext() = default;
    
    // 设备信息
    DeviceType device() const { return device_; }
    void set_device(DeviceType device) { device_ = device; }
    
    // 执行模式
    bool is_training() const { return is_training_; }
    void set_training(bool training) { is_training_ = training; }
    
    // 随机种子
    uint64_t random_seed() const { return random_seed_; }
    void set_random_seed(uint64_t seed) { random_seed_ = seed; }
    
    // 工作空间内存
    void* get_workspace(size_t size_bytes);
    void release_workspace();
    
private:
    DeviceType device_ = DeviceType::CPU;
    bool is_training_ = false;
    uint64_t random_seed_ = 42;
    std::unique_ptr<char[]> workspace_;
    size_t workspace_size_ = 0;
};

// 操作符注册系统
class OperatorRegistry {
public:
    using CreateFunction = std::function<std::unique_ptr<Operator>(const AttrMap&)>;
    
    static OperatorRegistry& instance();
    
    // 注册操作符
    void register_operator(const std::string& op_type, CreateFunction create_fn);
    
    // 创建操作符
    std::unique_ptr<Operator> create_operator(const std::string& op_type, 
                                             const AttrMap& attrs = {}) const;
    
    // 查询
    bool has_operator(const std::string& op_type) const;
    std::vector<std::string> list_operators() const;
    
private:
    std::unordered_map<std::string, CreateFunction> registry_;
};

// 注册宏
#define REGISTER_OPERATOR(op_type, op_class) \
    namespace { \
        struct op_class##_Register { \
            op_class##_Register() { \
                OperatorRegistry::instance().register_operator( \
                    #op_type, \
                    [](const AttrMap& attrs) -> std::unique_ptr<Operator> { \
                        auto op = std::make_unique<op_class>(); \
                        for (const auto& [key, value] : attrs) { \
                            op->set_attr(key, value); \
                        } \
                        return op; \
                    } \
                ); \
            } \
        }; \
        static op_class##_Register g_##op_class##_register; \
    }

// 元操作符基类 - 用于实现通用模式
template<typename Derived>
class ElementwiseOperator : public Operator {
public:
    std::vector<Shape> infer_shape(const std::vector<Shape>& input_shapes) const override {
        // 广播语义
        assert(!input_shapes.empty());
        Shape result_shape = input_shapes[0];
        for (size_t i = 1; i < input_shapes.size(); ++i) {
            result_shape = result_shape.broadcast_with(input_shapes[i]);
        }
        return {result_shape};
    }
    
    std::vector<DataType> infer_dtype(const std::vector<DataType>& input_dtypes) const override {
        // 默认返回第一个输入的类型
        assert(!input_dtypes.empty());
        return {input_dtypes[0]};
    }
    
    bool validate(const std::vector<Shape>& input_shapes,
                 const std::vector<DataType>& input_dtypes) const override {
        if (input_shapes.empty() || input_dtypes.empty()) return false;
        if (input_shapes.size() != input_dtypes.size()) return false;
        
        // 检查形状是否可以广播
        for (size_t i = 1; i < input_shapes.size(); ++i) {
            if (!input_shapes[0].is_broadcastable_with(input_shapes[i])) {
                return false;
            }
        }
        return true;
    }
};

template<typename Derived>
class ReductionOperator : public Operator {
public:
    std::vector<Shape> infer_shape(const std::vector<Shape>& input_shapes) const override {
        assert(input_shapes.size() == 1);
        const Shape& input_shape = input_shapes[0];
        
        // 获取归约维度
        std::vector<int64_t> axes;
        if (has_attr("axes")) {
            axes = std::get<std::vector<int64_t>>(get_attr("axes"));
        } else {
            // 默认归约所有维度
            for (int64_t i = 0; i < input_shape.rank(); ++i) {
                axes.push_back(i);
            }
        }
        
        bool keepdims = false;
        if (has_attr("keepdims")) {
            keepdims = std::get<bool>(get_attr("keepdims"));
        }
        
        std::vector<int64_t> output_dims;
        for (int64_t i = 0; i < input_shape.rank(); ++i) {
            bool is_reduction_axis = std::find(axes.begin(), axes.end(), i) != axes.end();
            if (!is_reduction_axis) {
                output_dims.push_back(input_shape[i]);
            } else if (keepdims) {
                output_dims.push_back(1);
            }
        }
        
        return {Shape(output_dims)};
    }
};

} // namespace minitvm
```

### 基础数学操作符

```cpp
// include/minitvm/operators/math_ops.h
#pragma once

#include "minitvm/core/operator.h"

namespace minitvm {
namespace ops {

// 加法操作符
class AddOperator : public ElementwiseOperator<AddOperator> {
public:
    std::string name() const override { return "add"; }
    std::string type() const override { return "Add"; }
    
    std::vector<Tensor> compute(const std::vector<Tensor>& inputs, 
                               const OpContext& ctx) const override;
    
    std::vector<Tensor> gradient(const std::vector<Tensor>& inputs,
                                const std::vector<Tensor>& grad_outputs,
                                const OpContext& ctx) const override;
};

// 乘法操作符
class MulOperator : public ElementwiseOperator<MulOperator> {
public:
    std::string name() const override { return "mul"; }
    std::string type() const override { return "Mul"; }
    
    std::vector<Tensor> compute(const std::vector<Tensor>& inputs, 
                               const OpContext& ctx) const override;
    
    std::vector<Tensor> gradient(const std::vector<Tensor>& inputs,
                                const std::vector<Tensor>& grad_outputs,
                                const OpContext& ctx) const override;
};

// 矩阵乘法操作符
class MatMulOperator : public Operator {
public:
    std::string name() const override { return "matmul"; }
    std::string type() const override { return "MatMul"; }
    
    std::vector<Shape> infer_shape(const std::vector<Shape>& input_shapes) const override;
    std::vector<DataType> infer_dtype(const std::vector<DataType>& input_dtypes) const override;
    
    std::vector<Tensor> compute(const std::vector<Tensor>& inputs, 
                               const OpContext& ctx) const override;
    
    std::vector<Tensor> gradient(const std::vector<Tensor>& inputs,
                                const std::vector<Tensor>& grad_outputs,
                                const OpContext& ctx) const override;
    
    bool validate(const std::vector<Shape>& input_shapes,
                 const std::vector<DataType>& input_dtypes) const override;
};

// 求和操作符
class SumOperator : public ReductionOperator<SumOperator> {
public:
    std::string name() const override { return "sum"; }
    std::string type() const override { return "Sum"; }
    
    std::vector<DataType> infer_dtype(const std::vector<DataType>& input_dtypes) const override {
        return {input_dtypes[0]}; // 保持输入类型
    }
    
    std::vector<Tensor> compute(const std::vector<Tensor>& inputs, 
                               const OpContext& ctx) const override;
    
    std::vector<Tensor> gradient(const std::vector<Tensor>& inputs,
                                const std::vector<Tensor>& grad_outputs,
                                const OpContext& ctx) const override;
};

// ReLU 激活函数
class ReLUOperator : public ElementwiseOperator<ReLUOperator> {
public:
    std::string name() const override { return "relu"; }
    std::string type() const override { return "ReLU"; }
    
    std::vector<Tensor> compute(const std::vector<Tensor>& inputs, 
                               const OpContext& ctx) const override;
    
    std::vector<Tensor> gradient(const std::vector<Tensor>& inputs,
                                const std::vector<Tensor>& grad_outputs,
                                const OpContext& ctx) const override;
};

// Softmax 激活函数
class SoftmaxOperator : public Operator {
public:
    std::string name() const override { return "softmax"; }
    std::string type() const override { return "Softmax"; }
    
    std::vector<Shape> infer_shape(const std::vector<Shape>& input_shapes) const override {
        return input_shapes; // 形状不变
    }
    
    std::vector<DataType> infer_dtype(const std::vector<DataType>& input_dtypes) const override {
        return input_dtypes; // 类型不变
    }
    
    std::vector<Tensor> compute(const std::vector<Tensor>& inputs, 
                               const OpContext& ctx) const override;
    
    std::vector<Tensor> gradient(const std::vector<Tensor>& inputs,
                                const std::vector<Tensor>& grad_outputs,
                                const OpContext& ctx) const override;
};

} // namespace ops
} // namespace minitvm
```

### 操作符实现

```cpp
// src/operators/math_ops.cpp
#include "minitvm/operators/math_ops.h"
#include <algorithm>
#include <cmath>

namespace minitvm {
namespace ops {

// CPU 计算内核 - 简化实现
namespace cpu_kernels {

template<typename T>
void add_kernel(const T* a, const T* b, T* out, int64_t size) {
    for (int64_t i = 0; i < size; ++i) {
        out[i] = a[i] + b[i];
    }
}

template<typename T>
void mul_kernel(const T* a, const T* b, T* out, int64_t size) {
    for (int64_t i = 0; i < size; ++i) {
        out[i] = a[i] * b[i];
    }
}

template<typename T>
void matmul_kernel(const T* a, const T* b, T* c, 
                   int64_t M, int64_t N, int64_t K) {
    // 简单的三重循环矩阵乘法
    for (int64_t i = 0; i < M; ++i) {
        for (int64_t j = 0; j < N; ++j) {
            T sum = 0;
            for (int64_t k = 0; k < K; ++k) {
                sum += a[i * K + k] * b[k * N + j];
            }
            c[i * N + j] = sum;
        }
    }
}

template<typename T>
void relu_kernel(const T* input, T* output, int64_t size) {
    for (int64_t i = 0; i < size; ++i) {
        output[i] = std::max(T(0), input[i]);
    }
}

template<typename T>
void sum_kernel(const T* input, T* output, int64_t size) {
    T sum = 0;
    for (int64_t i = 0; i < size; ++i) {
        sum += input[i];
    }
    *output = sum;
}

} // namespace cpu_kernels

// AddOperator 实现
std::vector<Tensor> AddOperator::compute(const std::vector<Tensor>& inputs, 
                                        const OpContext& ctx) const {
    assert(inputs.size() == 2);
    const auto& a = inputs[0];
    const auto& b = inputs[1];
    
    // 推导输出形状
    Shape output_shape = a.shape().broadcast_with(b.shape());
    Tensor output(output_shape, a.dtype(), ctx.device());
    
    // 根据设备类型选择计算内核
    if (ctx.device() == DeviceType::CPU) {
        if (a.dtype() == DataType::FLOAT32) {
            // 简化处理：假设输入已经广播到相同形状
            assert(a.numel() == b.numel() && a.numel() == output.numel());
            cpu_kernels::add_kernel(
                a.data<float>(), 
                b.data<float>(), 
                output.data<float>(), 
                output.numel()
            );
        }
        // 处理其他数据类型...
    }
    
    return {output};
}

std::vector<Tensor> AddOperator::gradient(const std::vector<Tensor>& inputs,
                                         const std::vector<Tensor>& grad_outputs,
                                         const OpContext& ctx) const {
    // 加法的梯度就是原样传播
    assert(grad_outputs.size() == 1);
    const auto& grad_output = grad_outputs[0];
    
    // 处理广播的情况
    std::vector<Tensor> grad_inputs;
    for (const auto& input : inputs) {
        if (input.shape() == grad_output.shape()) {
            grad_inputs.push_back(grad_output);
        } else {
            // 需要对梯度进行求和以匹配输入形状
            // TODO: 实现广播梯度的反向传播
            grad_inputs.push_back(grad_output); // 简化处理
        }
    }
    
    return grad_inputs;
}

// MatMulOperator 实现
std::vector<Shape> MatMulOperator::infer_shape(const std::vector<Shape>& input_shapes) const {
    assert(input_shapes.size() == 2);
    const auto& a_shape = input_shapes[0];
    const auto& b_shape = input_shapes[1];
    
    assert(a_shape.rank() >= 2 && b_shape.rank() >= 2);
    
    // 简化处理：只考虑2D矩阵乘法
    if (a_shape.rank() == 2 && b_shape.rank() == 2) {
        int64_t M = a_shape[0];
        int64_t K = a_shape[1];
        int64_t K2 = b_shape[0];
        int64_t N = b_shape[1];
        
        assert(K == K2); // 维度必须匹配
        
        return {Shape({M, N})};
    }
    
    // TODO: 处理批量矩阵乘法
    throw std::runtime_error("Batch matmul not implemented yet");
}

std::vector<DataType> MatMulOperator::infer_dtype(const std::vector<DataType>& input_dtypes) const {
    assert(input_dtypes.size() == 2);
    assert(input_dtypes[0] == input_dtypes[1]); // 简化：要求相同类型
    return {input_dtypes[0]};
}

std::vector<Tensor> MatMulOperator::compute(const std::vector<Tensor>& inputs, 
                                           const OpContext& ctx) const {
    assert(inputs.size() == 2);
    const auto& a = inputs[0];
    const auto& b = inputs[1];
    
    auto output_shapes = infer_shape({a.shape(), b.shape()});
    Tensor output(output_shapes[0], a.dtype(), ctx.device());
    
    if (ctx.device() == DeviceType::CPU && a.dtype() == DataType::FLOAT32) {
        int64_t M = a.shape()[0];
        int64_t K = a.shape()[1];
        int64_t N = b.shape()[1];
        
        cpu_kernels::matmul_kernel(
            a.data<float>(),
            b.data<float>(),
            output.data<float>(),
            M, N, K
        );
    }
    
    return {output};
}

bool MatMulOperator::validate(const std::vector<Shape>& input_shapes,
                             const std::vector<DataType>& input_dtypes) const {
    if (input_shapes.size() != 2 || input_dtypes.size() != 2) return false;
    
    const auto& a_shape = input_shapes[0];
    const auto& b_shape = input_shapes[1];
    
    if (a_shape.rank() < 2 || b_shape.rank() < 2) return false;
    
    // 检查矩阵乘法维度匹配
    if (a_shape[a_shape.rank() - 1] != b_shape[b_shape.rank() - 2]) {
        return false;
    }
    
    return input_dtypes[0] == input_dtypes[1];
}

// ReLUOperator 实现
std::vector<Tensor> ReLUOperator::compute(const std::vector<Tensor>& inputs, 
                                         const OpContext& ctx) const {
    assert(inputs.size() == 1);
    const auto& input = inputs[0];
    
    Tensor output(input.shape(), input.dtype(), ctx.device());
    
    if (ctx.device() == DeviceType::CPU && input.dtype() == DataType::FLOAT32) {
        cpu_kernels::relu_kernel(
            input.data<float>(),
            output.data<float>(),
            input.numel()
        );
    }
    
    return {output};
}

std::vector<Tensor> ReLUOperator::gradient(const std::vector<Tensor>& inputs,
                                          const std::vector<Tensor>& grad_outputs,
                                          const OpContext& ctx) const {
    assert(inputs.size() == 1 && grad_outputs.size() == 1);
    const auto& input = inputs[0];
    const auto& grad_output = grad_outputs[0];
    
    Tensor grad_input(input.shape(), input.dtype(), ctx.device());
    
    if (ctx.device() == DeviceType::CPU && input.dtype() == DataType::FLOAT32) {
        const float* input_data = input.data<float>();
        const float* grad_output_data = grad_output.data<float>();
        float* grad_input_data = grad_input.data<float>();
        
        for (int64_t i = 0; i < input.numel(); ++i) {
            grad_input_data[i] = (input_data[i] > 0) ? grad_output_data[i] : 0.0f;
        }
    }
    
    return {grad_input};
}

} // namespace ops
} // namespace minitvm

// 注册操作符
REGISTER_OPERATOR(Add, minitvm::ops::AddOperator);
REGISTER_OPERATOR(Mul, minitvm::ops::MulOperator);
REGISTER_OPERATOR(MatMul, minitvm::ops::MatMulOperator);
REGISTER_OPERATOR(Sum, minitvm::ops::SumOperator);
REGISTER_OPERATOR(ReLU, minitvm::ops::ReLUOperator);
REGISTER_OPERATOR(Softmax, minitvm::ops::SoftmaxOperator);
```

### 计算图实现

```cpp
// include/minitvm/core/graph.h
#pragma once

#include "tensor.h"
#include "operator.h"
#include <memory>
#include <vector>
#include <unordered_map>
#include <unordered_set>
#include <string>

namespace minitvm {

// 前置声明
class Graph;
class Node;

using NodePtr = std::shared_ptr<Node>;
using GraphPtr = std::shared_ptr<Graph>;

// 计算图中的节点
class Node : public std::enable_shared_from_this<Node> {
public:
    // 节点类型
    enum class Type {
        INPUT,      // 输入节点
        OPERATOR,   // 操作符节点
        CONSTANT,   // 常量节点
    };
    
    // 构造函数
    static NodePtr create_input(const std::string& name, const Shape& shape, DataType dtype);
    static NodePtr create_operator(std::unique_ptr<Operator> op, const std::vector<NodePtr>& inputs);
    static NodePtr create_constant(const Tensor& tensor, const std::string& name = "");
    
    // 基本属性
    Type type() const { return type_; }
    const std::string& name() const { return name_; }
    size_t id() const { return id_; }
    
    // 操作符相关
    const Operator* op() const { return op_.get(); }
    bool has_operator() const { return op_ != nullptr; }
    
    // 连接关系
    const std::vector<NodePtr>& inputs() const { return inputs_; }
    const std::vector<std::weak_ptr<Node>>& outputs() const { return outputs_; }
    void add_output(NodePtr output);
    void remove_output(NodePtr output);
    
    // 形状和类型信息
    const std::vector<Shape>& output_shapes() const { return output_shapes_; }
    const std::vector<DataType>& output_dtypes() const { return output_dtypes_; }
    void set_output_info(const std::vector<Shape>& shapes, const std::vector<DataType>& dtypes);
    
    // 常量数据
    const Tensor& constant_data() const;
    bool is_constant() const { return type_ == Type::CONSTANT; }
    
    // 运行时状态
    bool is_computed() const { return computed_; }
    void set_computed(bool computed) { computed_ = computed; }
    const std::vector<Tensor>& runtime_outputs() const { return runtime_outputs_; }
    void set_runtime_outputs(const std::vector<Tensor>& outputs) { runtime_outputs_ = outputs; }
    
    // 调试信息
    std::string to_string() const;
    void print_info() const;

private:
    // 私有构造函数
    Node(Type type, const std::string& name);
    
    static size_t next_id_;
    
    Type type_;
    std::string name_;
    size_t id_;
    
    // 操作符
    std::unique_ptr<Operator> op_;
    
    // 连接关系
    std::vector<NodePtr> inputs_;
    std::vector<std::weak_ptr<Node>> outputs_;
    
    // 类型信息
    std::vector<Shape> output_shapes_;
    std::vector<DataType> output_dtypes_;
    
    // 常量数据
    Tensor constant_data_;
    
    // 运行时状态
    bool computed_ = false;
    std::vector<Tensor> runtime_outputs_;
};

// 计算图
class Graph {
public:
    Graph(const std::string& name = "");
    
    // 基本属性
    const std::string& name() const { return name_; }
    void set_name(const std::string& name) { name_ = name; }
    
    // 节点管理
    void add_node(NodePtr node);
    void remove_node(NodePtr node);
    const std::vector<NodePtr>& nodes() const { return nodes_; }
    NodePtr get_node(size_t id) const;
    NodePtr get_node(const std::string& name) const;
    
    // 输入输出管理
    void add_input(NodePtr input);
    void add_output(NodePtr output);
    void set_inputs(const std::vector<NodePtr>& inputs);
    void set_outputs(const std::vector<NodePtr>& outputs);
    const std::vector<NodePtr>& inputs() const { return inputs_; }
    const std::vector<NodePtr>& outputs() const { return outputs_; }
    
    // 图分析
    void infer_shapes();
    void validate() const;
    std::vector<NodePtr> topological_sort() const;
    std::vector<std::vector<NodePtr>> get_execution_schedule() const;
    
    // 图优化
    void eliminate_dead_nodes();
    void constant_folding();
    void operator_fusion();
    
    // 执行
    std::vector<Tensor> execute(const std::vector<Tensor>& inputs, const OpContext& ctx = OpContext());
    
    // 可视化和调试
    std::string to_dot() const;
    void visualize(const std::string& filename) const;
    void print_statistics() const;
    
    // 序列化
    void save_to_file(const std::string& filename) const;
    static GraphPtr load_from_file(const std::string& filename);
    
private:
    std::string name_;
    std::vector<NodePtr> nodes_;
    std::vector<NodePtr> inputs_;
    std::vector<NodePtr> outputs_;
    
    std::unordered_map<size_t, NodePtr> id_to_node_;
    std::unordered_map<std::string, NodePtr> name_to_node_;
    
    void update_indices();
    bool has_cycle() const;
    void dfs_visit(NodePtr node, std::unordered_set<NodePtr>& visited, 
                   std::unordered_set<NodePtr>& rec_stack, std::vector<NodePtr>& result) const;
};

// 图构建器 - 提供便利的构建接口
class GraphBuilder {
public:
    explicit GraphBuilder(const std::string& graph_name = "");
    
    // 创建输入
    NodePtr input(const std::string& name, const Shape& shape, DataType dtype = DataType::FLOAT32);
    
    // 创建常量
    NodePtr constant(const Tensor& tensor, const std::string& name = "");
    
    // 数学操作
    NodePtr add(NodePtr a, NodePtr b);
    NodePtr mul(NodePtr a, NodePtr b);
    NodePtr matmul(NodePtr a, NodePtr b);
    NodePtr sum(NodePtr input, const std::vector<int64_t>& axes = {}, bool keepdims = false);
    
    // 激活函数
    NodePtr relu(NodePtr input);
    NodePtr softmax(NodePtr input, int64_t axis = -1);
    
    // 完成图构建
    GraphPtr finalize(const std::vector<NodePtr>& outputs);
    
private:
    GraphPtr graph_;
    
    NodePtr create_operator_node(const std::string& op_type, const std::vector<NodePtr>& inputs, 
                                 const AttrMap& attrs = {});
};

} // namespace minitvm
```

### 第二阶段测试

```cpp
// tests/unit/test_operators.cpp
#include <gtest/gtest.h>
#include "minitvm/core/operator.h"
#include "minitvm/operators/math_ops.h"
#include "minitvm/core/graph.h"

using namespace minitvm;

class OperatorTest : public ::testing::Test {
protected:
    void SetUp() override {
        ctx.set_device(DeviceType::CPU);
    }
    
    OpContext ctx;
};

TEST_F(OperatorTest, AddOperator) {
    auto add_op = std::make_unique<ops::AddOperator>();
    
    // 测试形状推导
    std::vector<Shape> input_shapes = {Shape({2, 3}), Shape({2, 3})};
    auto output_shapes = add_op->infer_shape(input_shapes);
    EXPECT_EQ(output_shapes.size(), 1);
    EXPECT_EQ(output_shapes[0], Shape({2, 3}));
    
    // 测试计算
    auto a = ones({2, 3}, DataType::FLOAT32);
    auto b = ones({2, 3}, DataType::FLOAT32);
    auto outputs = add_op->compute({a, b}, ctx);
    
    EXPECT_EQ(outputs.size(), 1);
    EXPECT_EQ(outputs[0].shape(), Shape({2, 3}));
    
    // 验证结果
    float* result_data = outputs[0].data<float>();
    for (int i = 0; i < 6; ++i) {
        EXPECT_FLOAT_EQ(result_data[i], 2.0f);
    }
}

TEST_F(OperatorTest, MatMulOperator) {
    auto matmul_op = std::make_unique<ops::MatMulOperator>();
    
    // 测试形状推导
    std::vector<Shape> input_shapes = {Shape({2, 3}), Shape({3, 4})};
    auto output_shapes = matmul_op->infer_shape(input_shapes);
    EXPECT_EQ(output_shapes[0], Shape({2, 4}));
    
    // 测试计算
    auto a = ones({2, 3}, DataType::FLOAT32);
    auto b = ones({3, 4}, DataType::FLOAT32);
    auto outputs = matmul_op->compute({a, b}, ctx);
    
    EXPECT_EQ(outputs[0].shape(), Shape({2, 4}));
    
    // 验证结果：每个元素应该是3.0（1*1 + 1*1 + 1*1）
    float* result_data = outputs[0].data<float>();
    for (int i = 0; i < 8; ++i) {
        EXPECT_FLOAT_EQ(result_data[i], 3.0f);
    }
}

TEST_F(OperatorTest, OperatorRegistry) {
    auto& registry = OperatorRegistry::instance();
    
    EXPECT_TRUE(registry.has_operator("Add"));
    EXPECT_TRUE(registry.has_operator("MatMul"));
    
    auto add_op = registry.create_operator("Add");
    EXPECT_TRUE(add_op != nullptr);
    EXPECT_EQ(add_op->type(), "Add");
}

class GraphTest : public ::testing::Test {
protected:
    void SetUp() override {}
};

TEST_F(GraphTest, BasicGraph) {
    GraphBuilder builder("test_graph");
    
    // 构建简单的计算图: y = (a + b) * c
    auto a = builder.input("a", {2, 3});
    auto b = builder.input("b", {2, 3});
    auto c = builder.input("c", {2, 3});
    
    auto add_result = builder.add(a, b);
    auto mul_result = builder.mul(add_result, c);
    
    auto graph = builder.finalize({mul_result});
    
    EXPECT_EQ(graph->inputs().size(), 3);
    EXPECT_EQ(graph->outputs().size(), 1);
    EXPECT_EQ(graph->nodes().size(), 5); // 3 inputs + 1 add + 1 mul
}

TEST_F(GraphTest, GraphExecution) {
    GraphBuilder builder("execution_test");
    
    auto a = builder.input("a", {2, 2});
    auto b = builder.input("b", {2, 2});
    auto result = builder.add(a, b);
    
    auto graph = builder.finalize({result});
    
    // 创建输入数据
    auto input_a = ones({2, 2}, DataType::FLOAT32);
    auto input_b = ones({2, 2}, DataType::FLOAT32);
    
    // 执行图
    auto outputs = graph->execute({input_a, input_b});
    
    EXPECT_EQ(outputs.size(), 1);
    EXPECT_EQ(outputs[0].shape(), Shape({2, 2}));
    
    // 验证结果
    float* result_data = outputs[0].data<float>();
    for (int i = 0; i < 4; ++i) {
        EXPECT_FLOAT_EQ(result_data[i], 2.0f);
    }
}

TEST_F(GraphTest, TopologicalSort) {
    GraphBuilder builder("topo_test");
    
    auto a = builder.input("a", {2, 2});
    auto b = builder.input("b", {2, 2});
    auto c = builder.input("c", {2, 2});
    
    auto ab = builder.add(a, b);
    auto abc = builder.add(ab, c);
    
    auto graph = builder.finalize({abc});
    
    auto sorted_nodes = graph->topological_sort();
    
    // 验证拓扑排序的正确性
    std::unordered_map<NodePtr, size_t> node_positions;
    for (size_t i = 0; i < sorted_nodes.size(); ++i) {
        node_positions[sorted_nodes[i]] = i;
    }
    
    for (const auto& node : sorted_nodes) {
        for (const auto& input : node->inputs()) {
            EXPECT_LT(node_positions[input], node_positions[node]);
        }
    }
}
```

---

## 第二阶段总结

### 已完成的功能

1. **完整的操作符系统**
   - 操作符基类和抽象接口
   - 注册机制和工厂模式
   - 元操作符模板（ElementwiseOperator, ReductionOperator）

2. **基础数学运算**
   - 加法、乘法、矩阵乘法
   - ReLU、Softmax 激活函数
   - 支持梯度计算

3. **计算图基础设施**
   - 节点表示和连接管理
   - 图构建和验证
   - 拓扑排序和执行调度

4. **便利工具**
   - GraphBuilder 提供简洁的构建接口
   - 形状推导和类型推导
   - 可视化和调试工具

### 学习要点

1. **设计模式深入应用**
   - 模板方法模式：ElementwiseOperator
   - 注册模式：OperatorRegistry
   - 建造者模式：GraphBuilder

2. **图算法应用**
   - 拓扑排序
   - 死代码消除
   - 依赖分析

3. **类型系统设计**
   - 形状推导算法
   - 广播语义实现
   - 类型兼容性检查

### 下一阶段预览

在第三阶段，我们将实现：
- 多级中间表示（IR）系统
- 图优化 Pass 框架
- 更高级的操作符（卷积、池化等）
- 自动微分系统的完整实现

这为构建一个功能完整的深度学习编译器奠定了坚实的基础。
