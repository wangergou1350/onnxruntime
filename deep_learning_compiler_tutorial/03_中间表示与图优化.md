# 第三阶段：中间表示（IR）与图优化

## 概述

第三阶段将构建 MiniTVM 的多级中间表示（IR）系统和图优化框架。这是深度学习编译器的核心，包括高级IR的定义、优化Pass的设计与实现、以及从高级到低级IR的降级过程。

## 实现计划

### Day 11-13: 多级IR系统
### Day 14-15: 图优化Pass框架  
### Day 16: 常用优化Pass实现

---

## Day 11-13: 多级IR系统

### IR层级设计

```cpp
// include/minitvm/ir/ir_base.h
#pragma once

#include "minitvm/core/types.h"
#include <memory>
#include <vector>
#include <string>
#include <unordered_map>
#include <variant>

namespace minitvm {
namespace ir {

// IR节点基类
class IRNode {
public:
    virtual ~IRNode() = default;
    virtual std::string type_key() const = 0;
    virtual std::string to_string() const = 0;
    virtual std::unique_ptr<IRNode> clone() const = 0;
    
    // 访问者模式支持
    template<typename T>
    T* as() { return dynamic_cast<T*>(this); }
    
    template<typename T>
    const T* as() const { return dynamic_cast<const T*>(this); }
    
    template<typename T>
    bool is() const { return as<T>() != nullptr; }
};

using IRNodePtr = std::shared_ptr<IRNode>;

// 表达式基类
class Expr : public IRNode {
public:
    DataType dtype() const { return dtype_; }
    void set_dtype(DataType dtype) { dtype_ = dtype; }
    
protected:
    DataType dtype_ = DataType::FLOAT32;
};

using ExprPtr = std::shared_ptr<Expr>;

// 语句基类  
class Stmt : public IRNode {
public:
    virtual void accept_visitor(class IRVisitor* visitor) = 0;
};

using StmtPtr = std::shared_ptr<Stmt>;

// 函数基类
class Function : public IRNode {
public:
    const std::string& name() const { return name_; }
    void set_name(const std::string& name) { name_ = name; }
    
    const std::vector<ExprPtr>& params() const { return params_; }
    void set_params(const std::vector<ExprPtr>& params) { params_ = params; }
    
    const StmtPtr& body() const { return body_; }
    void set_body(StmtPtr body) { body_ = body; }
    
    const std::vector<ExprPtr>& returns() const { return returns_; }
    void set_returns(const std::vector<ExprPtr>& returns) { returns_ = returns; }
    
protected:
    std::string name_;
    std::vector<ExprPtr> params_;
    StmtPtr body_;
    std::vector<ExprPtr> returns_;
};

using FunctionPtr = std::shared_ptr<Function>;

} // namespace ir
} // namespace minitvm
```

### 高级IR (Graph IR)

```cpp
// include/minitvm/ir/graph_ir.h
#pragma once

#include "ir_base.h"
#include "minitvm/core/shape.h"
#include <unordered_set>

namespace minitvm {
namespace ir {

// 图级别的IR - 用于图优化
class GraphIR {
public:
    struct Node {
        size_t id;
        std::string op_type;
        std::unordered_map<std::string, AttrValue> attrs;
        std::vector<size_t> inputs;  // 输入节点ID
        std::vector<Shape> output_shapes;
        std::vector<DataType> output_dtypes;
        
        std::string name() const;
        bool is_operator() const { return !op_type.empty(); }
    };
    
    GraphIR(const std::string& name = "");
    
    // 节点管理
    size_t add_node(const std::string& op_type = "", const AttrMap& attrs = {});
    void remove_node(size_t node_id);
    Node& get_node(size_t node_id);
    const Node& get_node(size_t node_id) const;
    
    // 边管理
    void add_edge(size_t from, size_t to);
    void remove_edge(size_t from, size_t to);
    
    // 图信息
    const std::string& name() const { return name_; }
    const std::unordered_map<size_t, Node>& nodes() const { return nodes_; }
    std::vector<size_t> get_inputs() const { return inputs_; }
    std::vector<size_t> get_outputs() const { return outputs_; }
    void set_inputs(const std::vector<size_t>& inputs) { inputs_ = inputs; }
    void set_outputs(const std::vector<size_t>& outputs) { outputs_ = outputs; }
    
    // 图分析
    std::vector<size_t> topological_sort() const;
    bool has_cycle() const;
    std::unordered_set<size_t> get_reachable_nodes(size_t start) const;
    
    // 优化相关
    void eliminate_dead_nodes();
    void constant_folding();
    
    // 序列化
    std::string to_json() const;
    static GraphIR from_json(const std::string& json);
    
private:
    std::string name_;
    std::unordered_map<size_t, Node> nodes_;
    std::vector<size_t> inputs_;
    std::vector<size_t> outputs_;
    size_t next_node_id_ = 0;
    
    void dfs_visit(size_t node_id, std::unordered_set<size_t>& visited,
                   std::unordered_set<size_t>& rec_stack, std::vector<size_t>& result) const;
};

// 从计算图转换为GraphIR
GraphIR graph_to_graph_ir(const Graph& graph);
Graph graph_ir_to_graph(const GraphIR& graph_ir);

} // namespace ir
} // namespace minitvm
```

### 中级IR (Tensor IR)

```cpp
// include/minitvm/ir/tensor_ir.h  
#pragma once

#include "ir_base.h"
#include "minitvm/core/shape.h"

namespace minitvm {
namespace ir {

// 变量表达式
class Var : public Expr {
public:
    explicit Var(const std::string& name, DataType dtype = DataType::FLOAT32);
    
    const std::string& name() const { return name_; }
    
    std::string type_key() const override { return "Var"; }
    std::string to_string() const override { return name_; }
    std::unique_ptr<IRNode> clone() const override;
    
private:
    std::string name_;
};

// 常量表达式
class IntImm : public Expr {
public:
    explicit IntImm(int64_t value);
    
    int64_t value() const { return value_; }
    
    std::string type_key() const override { return "IntImm"; }
    std::string to_string() const override;
    std::unique_ptr<IRNode> clone() const override;
    
private:
    int64_t value_;
};

class FloatImm : public Expr {
public:
    explicit FloatImm(double value);
    
    double value() const { return value_; }
    
    std::string type_key() const override { return "FloatImm"; }
    std::string to_string() const override;
    std::unique_ptr<IRNode> clone() const override;
    
private:
    double value_;
};

// 二元操作表达式
enum class BinaryOpType {
    ADD, SUB, MUL, DIV, MOD,
    EQ, NE, LT, LE, GT, GE,
    AND, OR,
    MAX, MIN
};

class BinaryOp : public Expr {
public:
    BinaryOp(BinaryOpType op_type, ExprPtr lhs, ExprPtr rhs);
    
    BinaryOpType op_type() const { return op_type_; }
    const ExprPtr& lhs() const { return lhs_; }
    const ExprPtr& rhs() const { return rhs_; }
    
    std::string type_key() const override { return "BinaryOp"; }
    std::string to_string() const override;
    std::unique_ptr<IRNode> clone() const override;
    
private:
    BinaryOpType op_type_;
    ExprPtr lhs_;
    ExprPtr rhs_;
};

// 一元操作表达式
enum class UnaryOpType {
    NEG, NOT, ABS, EXP, LOG, SQRT, SIN, COS, TANH
};

class UnaryOp : public Expr {
public:
    UnaryOp(UnaryOpType op_type, ExprPtr operand);
    
    UnaryOpType op_type() const { return op_type_; }
    const ExprPtr& operand() const { return operand_; }
    
    std::string type_key() const override { return "UnaryOp"; }
    std::string to_string() const override;
    std::unique_ptr<IRNode> clone() const override;
    
private:
    UnaryOpType op_type_;
    ExprPtr operand_;
};

// 选择表达式 (condition ? true_expr : false_expr)
class Select : public Expr {
public:
    Select(ExprPtr condition, ExprPtr true_expr, ExprPtr false_expr);
    
    const ExprPtr& condition() const { return condition_; }
    const ExprPtr& true_expr() const { return true_expr_; }
    const ExprPtr& false_expr() const { return false_expr_; }
    
    std::string type_key() const override { return "Select"; }
    std::string to_string() const override;
    std::unique_ptr<IRNode> clone() const override;
    
private:
    ExprPtr condition_;
    ExprPtr true_expr_;
    ExprPtr false_expr_;
};

// 函数调用表达式
class Call : public Expr {
public:
    Call(const std::string& name, const std::vector<ExprPtr>& args);
    
    const std::string& name() const { return name_; }
    const std::vector<ExprPtr>& args() const { return args_; }
    
    std::string type_key() const override { return "Call"; }
    std::string to_string() const override;
    std::unique_ptr<IRNode> clone() const override;
    
private:
    std::string name_;
    std::vector<ExprPtr> args_;
};

// 张量访问表达式 (tensor[indices])
class TensorLoad : public Expr {
public:
    TensorLoad(const std::string& tensor_name, const std::vector<ExprPtr>& indices);
    
    const std::string& tensor_name() const { return tensor_name_; }
    const std::vector<ExprPtr>& indices() const { return indices_; }
    
    std::string type_key() const override { return "TensorLoad"; }
    std::string to_string() const override;
    std::unique_ptr<IRNode> clone() const override;
    
private:
    std::string tensor_name_;
    std::vector<ExprPtr> indices_;
};

// 语句：张量存储 (tensor[indices] = value)
class TensorStore : public Stmt {
public:
    TensorStore(const std::string& tensor_name, const std::vector<ExprPtr>& indices, ExprPtr value);
    
    const std::string& tensor_name() const { return tensor_name_; }
    const std::vector<ExprPtr>& indices() const { return indices_; }
    const ExprPtr& value() const { return value_; }
    
    std::string type_key() const override { return "TensorStore"; }
    std::string to_string() const override;
    std::unique_ptr<IRNode> clone() const override;
    void accept_visitor(class IRVisitor* visitor) override;
    
private:
    std::string tensor_name_;
    std::vector<ExprPtr> indices_;
    ExprPtr value_;
};

// 语句：循环
class For : public Stmt {
public:
    enum class LoopType {
        SERIAL,      // 串行循环
        PARALLEL,    // 并行循环
        VECTORIZED,  // 向量化循环
        UNROLLED     // 展开循环
    };
    
    For(const std::string& loop_var, ExprPtr min, ExprPtr extent, 
        LoopType loop_type, StmtPtr body);
    
    const std::string& loop_var() const { return loop_var_; }
    const ExprPtr& min() const { return min_; }
    const ExprPtr& extent() const { return extent_; }
    LoopType loop_type() const { return loop_type_; }
    const StmtPtr& body() const { return body_; }
    
    void set_loop_type(LoopType loop_type) { loop_type_ = loop_type; }
    
    std::string type_key() const override { return "For"; }
    std::string to_string() const override;
    std::unique_ptr<IRNode> clone() const override;
    void accept_visitor(class IRVisitor* visitor) override;
    
private:
    std::string loop_var_;
    ExprPtr min_;
    ExprPtr extent_;
    LoopType loop_type_;
    StmtPtr body_;
};

// 语句：条件分支
class IfThenElse : public Stmt {
public:
    IfThenElse(ExprPtr condition, StmtPtr then_case, StmtPtr else_case = nullptr);
    
    const ExprPtr& condition() const { return condition_; }
    const StmtPtr& then_case() const { return then_case_; }
    const StmtPtr& else_case() const { return else_case_; }
    
    std::string type_key() const override { return "IfThenElse"; }
    std::string to_string() const override;
    std::unique_ptr<IRNode> clone() const override;
    void accept_visitor(class IRVisitor* visitor) override;
    
private:
    ExprPtr condition_;
    StmtPtr then_case_;
    StmtPtr else_case_;
};

// 语句：语句块
class Block : public Stmt {
public:
    explicit Block(const std::vector<StmtPtr>& stmts);
    
    const std::vector<StmtPtr>& stmts() const { return stmts_; }
    void add_stmt(StmtPtr stmt);
    
    std::string type_key() const override { return "Block"; }
    std::string to_string() const override;
    std::unique_ptr<IRNode> clone() const override;
    void accept_visitor(class IRVisitor* visitor) override;
    
private:
    std::vector<StmtPtr> stmts_;
};

// 语句：分配内存
class Allocate : public Stmt {
public:
    Allocate(const std::string& buffer_var, DataType dtype, 
             const std::vector<ExprPtr>& extents, StmtPtr body);
    
    const std::string& buffer_var() const { return buffer_var_; }
    DataType dtype() const { return dtype_; }
    const std::vector<ExprPtr>& extents() const { return extents_; }
    const StmtPtr& body() const { return body_; }
    
    std::string type_key() const override { return "Allocate"; }
    std::string to_string() const override;
    std::unique_ptr<IRNode> clone() const override;
    void accept_visitor(class IRVisitor* visitor) override;
    
private:
    std::string buffer_var_;
    DataType dtype_;
    std::vector<ExprPtr> extents_;
    StmtPtr body_;
};

// Tensor IR 函数
class TensorIRFunction : public Function {
public:
    TensorIRFunction(const std::string& name, const std::vector<std::string>& param_names,
                     const std::vector<Shape>& param_shapes, const std::vector<DataType>& param_dtypes);
    
    const std::vector<std::string>& param_names() const { return param_names_; }
    const std::vector<Shape>& param_shapes() const { return param_shapes_; }
    const std::vector<DataType>& param_dtypes() const { return param_dtypes_; }
    
    std::string type_key() const override { return "TensorIRFunction"; }
    std::string to_string() const override;
    std::unique_ptr<IRNode> clone() const override;
    
private:
    std::vector<std::string> param_names_;
    std::vector<Shape> param_shapes_;
    std::vector<DataType> param_dtypes_;
};

} // namespace ir
} // namespace minitvm
```

### 低级IR (LLVM IR接口)

```cpp
// include/minitvm/ir/llvm_ir.h
#pragma once

#include "tensor_ir.h"
#include <llvm/IR/Module.h>
#include <llvm/IR/IRBuilder.h>
#include <llvm/IR/LLVMContext.h>

namespace minitvm {
namespace ir {

// LLVM IR 代码生成器
class LLVMCodeGen {
public:
    LLVMCodeGen(const std::string& module_name);
    ~LLVMCodeGen();
    
    // 编译TensorIR函数到LLVM IR
    llvm::Function* compile_function(const TensorIRFunction& tir_func);
    
    // 获取生成的模块
    llvm::Module* get_module() const { return module_.get(); }
    
    // 代码生成
    std::string emit_llvm_ir() const;
    std::string emit_assembly() const;
    
    // JIT编译和执行
    void* compile_and_get_function_pointer(const std::string& func_name);
    
private:
    std::unique_ptr<llvm::LLVMContext> context_;
    std::unique_ptr<llvm::Module> module_;
    std::unique_ptr<llvm::IRBuilder<>> builder_;
    
    // 访问者模式实现代码生成
    class CodeGenVisitor;
    std::unique_ptr<CodeGenVisitor> visitor_;
    
    // 类型转换
    llvm::Type* get_llvm_type(DataType dtype);
    
    // 内存管理
    llvm::Value* create_tensor_alloca(const std::string& name, const Shape& shape, DataType dtype);
    llvm::Value* get_tensor_element_ptr(llvm::Value* tensor_ptr, const std::vector<llvm::Value*>& indices,
                                       const Shape& shape);
};

// CUDA C++ 代码生成器
class CUDACodeGen {
public:
    CUDACodeGen();
    
    // 编译TensorIR函数到CUDA C++
    std::string compile_function(const TensorIRFunction& tir_func);
    
    // 生成kernel启动代码
    std::string generate_kernel_launch(const TensorIRFunction& tir_func);
    
private:
    class CUDACodeGenVisitor;
    std::unique_ptr<CUDACodeGenVisitor> visitor_;
    
    // CUDA特定的代码生成
    std::string generate_thread_indexing(const std::vector<ExprPtr>& loop_indices);
    std::string generate_shared_memory_allocation(const std::vector<std::string>& buffers);
};

} // namespace ir
} // namespace minitvm
```

---

## Day 14-15: 图优化Pass框架

### Pass基础框架

```cpp
// include/minitvm/pass/pass_base.h
#pragma once

#include "minitvm/ir/graph_ir.h"
#include "minitvm/ir/tensor_ir.h"
#include <string>
#include <memory>
#include <vector>
#include <unordered_map>

namespace minitvm {
namespace pass {

// Pass信息
struct PassInfo {
    std::string name;
    std::string description;
    std::vector<std::string> required_passes;  // 依赖的Pass
    std::vector<std::string> invalidated_passes; // 会使其他Pass失效
    int priority = 0;  // 优先级
};

// Pass基类
class Pass {
public:
    virtual ~Pass() = default;
    
    const PassInfo& info() const { return info_; }
    
    // 核心接口
    virtual bool run_on_graph(ir::GraphIR& graph) = 0;
    virtual bool run_on_function(ir::TensorIRFunction& func) { return false; }
    
    // Pass配置
    void set_option(const std::string& key, const std::variant<int, double, bool, std::string>& value);
    template<typename T>
    T get_option(const std::string& key, const T& default_value = T{}) const;
    
    // 统计信息
    struct Statistics {
        size_t nodes_removed = 0;
        size_t nodes_added = 0;
        size_t nodes_modified = 0;
        double execution_time_ms = 0.0;
        std::unordered_map<std::string, int> custom_stats;
    };
    
    const Statistics& stats() const { return stats_; }
    void reset_stats() { stats_ = Statistics{}; }
    
protected:
    Pass(const PassInfo& info) : info_(info) {}
    
    PassInfo info_;
    std::unordered_map<std::string, std::variant<int, double, bool, std::string>> options_;
    Statistics stats_;
};

using PassPtr = std::unique_ptr<Pass>;

// Graph级别的Pass
class GraphPass : public Pass {
public:
    bool run_on_function(ir::TensorIRFunction& func) override final { return false; }
    
protected:
    GraphPass(const PassInfo& info) : Pass(info) {}
};

// Function级别的Pass
class FunctionPass : public Pass {
public:
    bool run_on_graph(ir::GraphIR& graph) override final;
    
protected:
    FunctionPass(const PassInfo& info) : Pass(info) {}
};

// Pass管理器
class PassManager {
public:
    PassManager() = default;
    
    // Pass注册和管理
    void register_pass(PassPtr pass);
    void add_pass(const std::string& pass_name);
    void remove_pass(const std::string& pass_name);
    
    // Pass配置
    void set_pass_option(const std::string& pass_name, const std::string& option, 
                        const std::variant<int, double, bool, std::string>& value);
    
    // 运行Pass流水线
    bool run_on_graph(ir::GraphIR& graph);
    bool run_on_function(ir::TensorIRFunction& func);
    
    // Pass依赖解析
    std::vector<std::string> resolve_pass_dependencies(const std::vector<std::string>& requested_passes);
    
    // 统计和调试
    void print_pass_statistics() const;
    void enable_pass_timing(bool enable) { timing_enabled_ = enable; }
    void enable_pass_verification(bool enable) { verification_enabled_ = enable; }
    
private:
    std::unordered_map<std::string, PassPtr> registered_passes_;
    std::vector<std::string> pass_pipeline_;
    bool timing_enabled_ = false;
    bool verification_enabled_ = true;
    
    bool verify_graph(const ir::GraphIR& graph) const;
    bool verify_function(const ir::TensorIRFunction& func) const;
};

// Pass注册宏
#define REGISTER_PASS(pass_class, pass_name, description) \
    namespace { \
        struct pass_class##_Register { \
            pass_class##_Register() { \
                PassInfo info; \
                info.name = pass_name; \
                info.description = description; \
                /* 其他Pass特定信息由构造函数设置 */ \
                auto pass = std::make_unique<pass_class>(info); \
                PassRegistry::instance().register_pass(std::move(pass)); \
            } \
        }; \
        static pass_class##_Register g_##pass_class##_register; \
    }

// Pass注册表
class PassRegistry {
public:
    static PassRegistry& instance();
    
    void register_pass(PassPtr pass);
    PassPtr create_pass(const std::string& name) const;
    std::vector<std::string> list_passes() const;
    
private:
    std::unordered_map<std::string, std::function<PassPtr()>> registry_;
};

} // namespace pass
} // namespace minitvm
```

### Pass分析工具

```cpp
// include/minitvm/pass/analysis.h
#pragma once

#include "pass_base.h"
#include <unordered_set>

namespace minitvm {
namespace pass {

// 控制流分析
class ControlFlowAnalysis {
public:
    struct BasicBlock {
        size_t id;
        std::vector<size_t> predecessors;
        std::vector<size_t> successors;
        std::vector<size_t> nodes;  // GraphIR节点ID
    };
    
    explicit ControlFlowAnalysis(const ir::GraphIR& graph);
    
    const std::vector<BasicBlock>& basic_blocks() const { return basic_blocks_; }
    std::vector<size_t> get_dominators(size_t block_id) const;
    bool dominates(size_t dominator, size_t node) const;
    
private:
    std::vector<BasicBlock> basic_blocks_;
    std::unordered_map<size_t, size_t> node_to_block_;
    
    void build_basic_blocks(const ir::GraphIR& graph);
    void compute_dominators();
};

// 数据流分析
class DataFlowAnalysis {
public:
    explicit DataFlowAnalysis(const ir::GraphIR& graph);
    
    // 到达定义分析
    std::unordered_set<size_t> get_reaching_definitions(size_t node_id) const;
    
    // 活跃变量分析
    std::unordered_set<size_t> get_live_variables(size_t node_id) const;
    
    // 使用-定义链
    std::vector<size_t> get_use_def_chain(size_t use_node) const;
    std::vector<size_t> get_def_use_chain(size_t def_node) const;
    
private:
    const ir::GraphIR& graph_;
    std::unordered_map<size_t, std::unordered_set<size_t>> reaching_defs_;
    std::unordered_map<size_t, std::unordered_set<size_t>> live_vars_;
    
    void compute_reaching_definitions();
    void compute_live_variables();
};

// 循环分析
class LoopAnalysis {
public:
    struct LoopInfo {
        size_t header;  // 循环头
        std::unordered_set<size_t> body;  // 循环体节点
        std::vector<size_t> back_edges;  // 回边
        LoopInfo* parent = nullptr;  // 父循环
        std::vector<std::unique_ptr<LoopInfo>> children;  // 子循环
    };
    
    explicit LoopAnalysis(const ir::GraphIR& graph);
    
    const std::vector<std::unique_ptr<LoopInfo>>& top_level_loops() const { return top_level_loops_; }
    LoopInfo* get_loop_for_node(size_t node_id) const;
    int get_loop_depth(size_t node_id) const;
    
private:
    std::vector<std::unique_ptr<LoopInfo>> top_level_loops_;
    std::unordered_map<size_t, LoopInfo*> node_to_loop_;
    
    void detect_natural_loops(const ir::GraphIR& graph);
    void build_loop_hierarchy();
};

// 别名分析 - 分析张量访问的别名关系
class AliasAnalysis {
public:
    enum class AliasResult {
        NO_ALIAS,      // 肯定不别名
        MAY_ALIAS,     // 可能别名
        MUST_ALIAS     // 肯定别名
    };
    
    explicit AliasAnalysis(const ir::GraphIR& graph);
    
    AliasResult query_alias(size_t node1, size_t node2) const;
    std::unordered_set<size_t> get_alias_set(size_t node_id) const;
    
private:
    const ir::GraphIR& graph_;
    std::unordered_map<std::pair<size_t, size_t>, AliasResult, 
                      boost::hash<std::pair<size_t, size_t>>> alias_cache_;
    
    AliasResult compute_alias(size_t node1, size_t node2) const;
};

} // namespace pass
} // namespace minitvm
```

---

## Day 16: 常用优化Pass实现

### 死代码消除

```cpp
// include/minitvm/pass/dead_code_elimination.h
#pragma once

#include "pass_base.h"

namespace minitvm {
namespace pass {

class DeadCodeEliminationPass : public GraphPass {
public:
    DeadCodeEliminationPass();
    
    bool run_on_graph(ir::GraphIR& graph) override;
    
private:
    // 标记可达节点
    void mark_reachable_nodes(const ir::GraphIR& graph, 
                             std::unordered_set<size_t>& reachable) const;
    
    // 检查节点是否有副作用
    bool has_side_effects(const ir::GraphIR::Node& node) const;
    
    // 移除死节点
    void remove_dead_nodes(ir::GraphIR& graph, 
                          const std::unordered_set<size_t>& reachable);
};

} // namespace pass
} // namespace minitvm
```

```cpp
// src/pass/dead_code_elimination.cpp
#include "minitvm/pass/dead_code_elimination.h"
#include <queue>

namespace minitvm {
namespace pass {

DeadCodeEliminationPass::DeadCodeEliminationPass() 
    : GraphPass({"dead_code_elimination", "Remove unreachable and unused nodes", {}, {}, 1}) {
}

bool DeadCodeEliminationPass::run_on_graph(ir::GraphIR& graph) {
    auto start_time = std::chrono::high_resolution_clock::now();
    
    std::unordered_set<size_t> reachable;
    mark_reachable_nodes(graph, reachable);
    
    size_t original_node_count = graph.nodes().size();
    remove_dead_nodes(graph, reachable);
    size_t final_node_count = graph.nodes().size();
    
    stats_.nodes_removed = original_node_count - final_node_count;
    
    auto end_time = std::chrono::high_resolution_clock::now();
    stats_.execution_time_ms = std::chrono::duration<double, std::milli>(end_time - start_time).count();
    
    return stats_.nodes_removed > 0;
}

void DeadCodeEliminationPass::mark_reachable_nodes(const ir::GraphIR& graph, 
                                                  std::unordered_set<size_t>& reachable) const {
    std::queue<size_t> worklist;
    
    // 从输出节点开始标记
    for (size_t output_id : graph.get_outputs()) {
        if (reachable.find(output_id) == reachable.end()) {
            reachable.insert(output_id);
            worklist.push(output_id);
        }
    }
    
    // 标记所有有副作用的节点
    for (const auto& [node_id, node] : graph.nodes()) {
        if (has_side_effects(node)) {
            if (reachable.find(node_id) == reachable.end()) {
                reachable.insert(node_id);
                worklist.push(node_id);
            }
        }
    }
    
    // 反向遍历标记所有可达节点
    while (!worklist.empty()) {
        size_t current = worklist.front();
        worklist.pop();
        
        const auto& node = graph.get_node(current);
        for (size_t input_id : node.inputs) {
            if (reachable.find(input_id) == reachable.end()) {
                reachable.insert(input_id);
                worklist.push(input_id);
            }
        }
    }
}

bool DeadCodeEliminationPass::has_side_effects(const ir::GraphIR::Node& node) const {
    // 具有副作用的操作符类型
    static const std::unordered_set<std::string> side_effect_ops = {
        "Print", "Assert", "Debug", "Alloc", "Free"
    };
    
    return side_effect_ops.find(node.op_type) != side_effect_ops.end();
}

void DeadCodeEliminationPass::remove_dead_nodes(ir::GraphIR& graph, 
                                               const std::unordered_set<size_t>& reachable) {
    std::vector<size_t> to_remove;
    
    for (const auto& [node_id, node] : graph.nodes()) {
        if (reachable.find(node_id) == reachable.end()) {
            to_remove.push_back(node_id);
        }
    }
    
    for (size_t node_id : to_remove) {
        graph.remove_node(node_id);
    }
}

REGISTER_PASS(DeadCodeEliminationPass, "dead_code_elimination", "Remove unreachable and unused nodes");

} // namespace pass
} // namespace minitvm
```

### 常量折叠

```cpp
// include/minitvm/pass/constant_folding.h
#pragma once

#include "pass_base.h"
#include "minitvm/core/tensor.h"

namespace minitvm {
namespace pass {

class ConstantFoldingPass : public GraphPass {
public:
    ConstantFoldingPass();
    
    bool run_on_graph(ir::GraphIR& graph) override;
    
private:
    // 检查节点是否可以折叠
    bool can_fold_node(const ir::GraphIR& graph, size_t node_id) const;
    
    // 执行常量计算
    std::vector<Tensor> evaluate_node(const ir::GraphIR& graph, size_t node_id);
    
    // 创建常量节点
    size_t create_constant_node(ir::GraphIR& graph, const Tensor& tensor);
    
    // 支持的可折叠操作
    std::unordered_set<std::string> foldable_ops_;
};

} // namespace pass
} // namespace minitvm
```

### 操作符融合

```cpp
// include/minitvm/pass/operator_fusion.h
#pragma once

#include "pass_base.h"

namespace minitvm {
namespace pass {

class OperatorFusionPass : public GraphPass {
public:
    OperatorFusionPass();
    
    bool run_on_graph(ir::GraphIR& graph) override;
    
private:
    // 融合模式
    struct FusionPattern {
        std::string name;
        std::vector<std::string> op_sequence;  // 操作符序列
        std::string fused_op_type;  // 融合后的操作符类型
        std::function<bool(const ir::GraphIR&, const std::vector<size_t>&)> matcher;
    };
    
    std::vector<FusionPattern> patterns_;
    
    // 初始化融合模式
    void initialize_patterns();
    
    // 查找融合机会
    std::vector<std::vector<size_t>> find_fusion_opportunities(const ir::GraphIR& graph) const;
    
    // 执行融合
    void apply_fusion(ir::GraphIR& graph, const std::vector<size_t>& nodes_to_fuse,
                     const std::string& fused_op_type);
    
    // 常见融合模式
    bool match_conv_bn_relu(const ir::GraphIR& graph, const std::vector<size_t>& nodes) const;
    bool match_elementwise_chain(const ir::GraphIR& graph, const std::vector<size_t>& nodes) const;
};

} // namespace pass
} // namespace minitvm
```

### 内存优化

```cpp
// include/minitvm/pass/memory_optimization.h
#pragma once

#include "pass_base.h"
#include "analysis.h"

namespace minitvm {
namespace pass {

class MemoryOptimizationPass : public GraphPass {
public:
    MemoryOptimizationPass();
    
    bool run_on_graph(ir::GraphIR& graph) override;
    
private:
    // 内存池分配
    struct MemoryPool {
        size_t total_size = 0;
        std::vector<std::pair<size_t, size_t>> allocations;  // (offset, size)
        std::unordered_map<size_t, size_t> node_to_offset;
    };
    
    // 生命周期分析
    struct LifetimeInfo {
        size_t first_use;
        size_t last_use;
        size_t memory_size;
    };
    
    // 分析张量生命周期
    std::unordered_map<size_t, LifetimeInfo> analyze_tensor_lifetimes(const ir::GraphIR& graph) const;
    
    // 内存池分配算法
    MemoryPool allocate_memory_pool(const std::unordered_map<size_t, LifetimeInfo>& lifetimes) const;
    
    // 插入内存管理节点
    void insert_memory_management_nodes(ir::GraphIR& graph, const MemoryPool& pool);
    
    // 就地操作优化
    void optimize_inplace_operations(ir::GraphIR& graph);
};

} // namespace pass
} // namespace minitvm
```

### Pass使用示例

```cpp
// tests/integration/test_pass_pipeline.cpp
#include <gtest/gtest.h>
#include "minitvm/pass/pass_base.h"
#include "minitvm/pass/dead_code_elimination.h"
#include "minitvm/pass/constant_folding.h"
#include "minitvm/pass/operator_fusion.h"
#include "minitvm/ir/graph_ir.h"

using namespace minitvm;

class PassPipelineTest : public ::testing::Test {
protected:
    void SetUp() override {
        // 创建测试图
        graph_ = create_test_graph();
        
        // 配置Pass管理器
        pass_manager_.register_pass(std::make_unique<pass::DeadCodeEliminationPass>());
        pass_manager_.register_pass(std::make_unique<pass::ConstantFoldingPass>());
        pass_manager_.register_pass(std::make_unique<pass::OperatorFusionPass>());
        
        pass_manager_.enable_pass_timing(true);
        pass_manager_.enable_pass_verification(true);
    }
    
    ir::GraphIR create_test_graph() {
        // 创建包含死代码和常量的测试图
        ir::GraphIR graph("test_graph");
        
        // 输入节点
        auto input1 = graph.add_node("", {}); // 输入节点
        auto input2 = graph.add_node("", {}); // 输入节点
        
        // 常量节点
        auto const1 = graph.add_node("Constant", {{"value", 1.0f}});
        auto const2 = graph.add_node("Constant", {{"value", 2.0f}});
        
        // 操作节点
        auto add1 = graph.add_node("Add", {});
        graph.add_edge(const1, add1);  // const1 + const2 (可折叠)
        graph.add_edge(const2, add1);
        
        auto add2 = graph.add_node("Add", {});
        graph.add_edge(input1, add2);  // input1 + add1
        graph.add_edge(add1, add2);
        
        auto dead_node = graph.add_node("Mul", {});  // 死节点
        graph.add_edge(input2, dead_node);
        
        graph.set_inputs({input1, input2});
        graph.set_outputs({add2});  // dead_node不在输出中
        
        return graph;
    }
    
    ir::GraphIR graph_;
    pass::PassManager pass_manager_;
};

TEST_F(PassPipelineTest, DeadCodeElimination) {
    size_t original_nodes = graph_.nodes().size();
    
    pass_manager_.add_pass("dead_code_elimination");
    bool changed = pass_manager_.run_on_graph(graph_);
    
    EXPECT_TRUE(changed);
    EXPECT_LT(graph_.nodes().size(), original_nodes);
    
    pass_manager_.print_pass_statistics();
}

TEST_F(PassPipelineTest, ConstantFolding) {
    pass_manager_.add_pass("constant_folding");
    bool changed = pass_manager_.run_on_graph(graph_);
    
    EXPECT_TRUE(changed);
    
    // 验证常量被折叠
    bool found_folded_constant = false;
    for (const auto& [id, node] : graph_.nodes()) {
        if (node.op_type == "Constant") {
            auto value = std::get<float>(node.attrs.at("value"));
            if (value == 3.0f) {  // 1.0 + 2.0 = 3.0
                found_folded_constant = true;
                break;
            }
        }
    }
    EXPECT_TRUE(found_folded_constant);
}

TEST_F(PassPipelineTest, FullPipeline) {
    // 运行完整的优化流水线
    pass_manager_.add_pass("constant_folding");
    pass_manager_.add_pass("dead_code_elimination");
    pass_manager_.add_pass("operator_fusion");
    
    size_t original_nodes = graph_.nodes().size();
    
    bool changed = pass_manager_.run_on_graph(graph_);
    
    EXPECT_TRUE(changed);
    EXPECT_LE(graph_.nodes().size(), original_nodes);
    
    // 验证图仍然有效
    graph_.validate();
    
    pass_manager_.print_pass_statistics();
}

TEST_F(PassPipelineTest, PassDependencies) {
    // 测试Pass依赖解析
    std::vector<std::string> requested = {"operator_fusion", "constant_folding"};
    auto resolved = pass_manager_.resolve_pass_dependencies(requested);
    
    // 应该按正确顺序排列
    auto cf_pos = std::find(resolved.begin(), resolved.end(), "constant_folding");
    auto of_pos = std::find(resolved.begin(), resolved.end(), "operator_fusion");
    
    EXPECT_LT(cf_pos, of_pos); // 常量折叠应该在操作符融合之前
}
```

---

## 第三阶段总结

### 已完成的功能

1. **多级IR系统**
   - IR节点基类和类型系统
   - 高级GraphIR用于图级优化
   - 中级TensorIR用于张量操作表示
   - 低级LLVM IR和CUDA代码生成接口

2. **Pass优化框架**
   - Pass基类和Pass管理器
   - Pass依赖解析和流水线执行
   - Pass统计和性能分析

3. **分析工具**
   - 控制流分析（支配关系）
   - 数据流分析（活跃变量、到达定义）
   - 循环分析（自然循环检测）
   - 别名分析（内存访问分析）

4. **核心优化Pass**
   - 死代码消除
   - 常量折叠
   - 操作符融合
   - 内存优化

### 学习要点

1. **编译器设计原理**
   - 多级IR的设计思想和转换
   - Pass基础设施和优化框架
   - 数据流和控制流分析

2. **高级算法应用**
   - 图算法（支配树、循环检测）
   - 数据流分析算法
   - 启发式优化算法

3. **设计模式**
   - 访问者模式（IR遍历）
   - 策略模式（不同优化策略）
   - 责任链模式（Pass流水线）

### 下一阶段预览

第四阶段将实现代码生成和运行时系统：
- 目标代码生成（CPU、GPU）
- 运行时内存管理
- 执行引擎和JIT编译
- 性能分析和调优工具

这构成了深度学习编译器的完整后端，使整个系统能够生成高性能的可执行代码。
