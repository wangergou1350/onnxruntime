# AI芯片算子开发四大核心模块入门教程

## 概述
本教程提供四个核心开源项目的入门指导，帮助您快速上手AI芯片算子开发的关键技术栈。

---

## 模块一：ONNXRuntime入门教程

### 快速开始 (30分钟)

#### 环境搭建
```bash
# 1. 安装ONNXRuntime
pip install onnxruntime
# GPU版本
pip install onnxruntime-gpu

# 2. 验证安装
python -c "import onnxruntime; print(onnxruntime.__version__)"
```

#### 第一个推理程序
```python
import onnxruntime as ort
import numpy as np

# 创建推理会话
session = ort.InferenceSession("model.onnx")

# 准备输入数据
input_name = session.get_inputs()[0].name
input_data = np.random.randn(1, 3, 224, 224).astype(np.float32)

# 运行推理
outputs = session.run(None, {input_name: input_data})
print("输出形状:", outputs[0].shape)
```

### 核心概念理解 (1小时)

#### 1. ExecutionProvider概念
```python
# 查看可用的执行提供者
providers = ort.get_available_providers()
print("可用提供者:", providers)

# 指定执行提供者
session = ort.InferenceSession("model.onnx", 
                              providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])
```

#### 2. 图优化选项
```python
# 设置优化级别
sess_options = ort.SessionOptions()
sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL

# 启用特定优化
sess_options.optimized_model_filepath = "optimized_model.onnx"

session = ort.InferenceSession("model.onnx", sess_options)
```

#### 3. 性能分析
```python
# 启用性能分析
sess_options.enable_profiling = True
session = ort.InferenceSession("model.onnx", sess_options)

# 运行推理
outputs = session.run(None, {input_name: input_data})

# 获取性能报告
prof_file = session.end_profiling()
print(f"性能报告保存到: {prof_file}")
```

### 实践项目 (2小时)
```python
# 项目：模型性能对比工具
import time
import onnxruntime as ort

class ModelBenchmark:
    def __init__(self, model_path):
        self.model_path = model_path
        self.sessions = {}
        
    def create_session(self, provider_name, provider_config=None):
        """创建不同提供者的会话"""
        providers = [provider_name]
        if provider_config:
            providers = [(provider_name, provider_config)]
            
        session = ort.InferenceSession(self.model_path, providers=providers)
        self.sessions[provider_name] = session
        return session
    
    def benchmark(self, input_data, iterations=100):
        """基准测试"""
        results = {}
        
        for name, session in self.sessions.items():
            input_name = session.get_inputs()[0].name
            
            # 预热
            for _ in range(10):
                session.run(None, {input_name: input_data})
            
            # 测试
            start_time = time.time()
            for _ in range(iterations):
                outputs = session.run(None, {input_name: input_data})
            end_time = time.time()
            
            avg_time = (end_time - start_time) / iterations * 1000  # ms
            results[name] = avg_time
            
        return results

# 使用示例
benchmark = ModelBenchmark("resnet50.onnx")
benchmark.create_session("CPUExecutionProvider")
benchmark.create_session("CUDAExecutionProvider")

input_data = np.random.randn(1, 3, 224, 224).astype(np.float32)
results = benchmark.benchmark(input_data)

for provider, time_ms in results.items():
    print(f"{provider}: {time_ms:.2f} ms")
```

---

## 模块二：Triton入门教程

### 快速开始 (30分钟)

#### 环境搭建
```bash
# 安装Triton
pip install triton

# 验证安装
python -c "import triton; print('Triton installed successfully')"
```

#### 第一个Triton内核
```python
import torch
import triton
import triton.language as tl

@triton.jit
def add_kernel(x_ptr, y_ptr, output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):
    """向量加法内核"""
    # 获取程序ID
    pid = tl.program_id(axis=0)
    
    # 计算偏移量
    block_start = pid * BLOCK_SIZE
    offsets = block_start + tl.arange(0, BLOCK_SIZE)
    
    # 边界检查
    mask = offsets < n_elements
    
    # 加载数据
    x = tl.load(x_ptr + offsets, mask=mask)
    y = tl.load(y_ptr + offsets, mask=mask)
    
    # 计算
    output = x + y
    
    # 存储结果
    tl.store(output_ptr + offsets, output, mask=mask)

def add(x: torch.Tensor, y: torch.Tensor):
    """向量加法包装函数"""
    output = torch.empty_like(x)
    n_elements = output.numel()
    
    # 启动配置
    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)
    
    # 启动内核
    add_kernel[grid](x, y, output, n_elements, BLOCK_SIZE=1024)
    
    return output

# 测试
x = torch.randn(100000, device='cuda')
y = torch.randn(100000, device='cuda')
output = add(x, y)
print("结果正确性:", torch.allclose(output, x + y))
```

### 核心概念理解 (1小时)

#### 1. 块级编程模型
```python
@triton.jit
def matrix_mul_kernel(
    a_ptr, b_ptr, c_ptr,
    M, N, K,
    stride_am, stride_ak,
    stride_bk, stride_bn,
    stride_cm, stride_cn,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    BLOCK_SIZE_K: tl.constexpr,
):
    """矩阵乘法内核"""
    # 程序ID
    pid = tl.program_id(axis=0)
    
    # 计算块索引
    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
    
    pid_m = pid // num_pid_n
    pid_n = pid % num_pid_n
    
    # 偏移量计算
    offs_am = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)
    offs_bn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)
    offs_k = tl.arange(0, BLOCK_SIZE_K)
    
    # 指针计算
    a_ptrs = a_ptr + offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak
    b_ptrs = b_ptr + offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn
    
    # 累加器
    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
    
    # K维度循环
    for k in range(0, K, BLOCK_SIZE_K):
        # 边界检查
        mask_a = (offs_am[:, None] < M) & ((k + offs_k)[None, :] < K)
        mask_b = ((k + offs_k)[:, None] < K) & (offs_bn[None, :] < N)
        
        # 加载数据
        a = tl.load(a_ptrs, mask=mask_a, other=0.0)
        b = tl.load(b_ptrs, mask=mask_b, other=0.0)
        
        # 计算
        accumulator += tl.dot(a, b)
        
        # 更新指针
        a_ptrs += BLOCK_SIZE_K * stride_ak
        b_ptrs += BLOCK_SIZE_K * stride_bk
    
    # 存储结果
    c = accumulator.to(tl.float16)
    
    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)
    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)
    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]
    
    mask_c = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
    tl.store(c_ptrs, c, mask=mask_c)
```

#### 2. 自动调优
```python
@triton.autotune(
    configs=[
        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_stages=3, num_warps=8),
        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32}, num_stages=5, num_warps=2),
        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_stages=5, num_warps=2),
    ],
    key=['M', 'N', 'K'],
)
@triton.jit
def optimized_matmul_kernel(
    # 参数与上面相同
    a_ptr, b_ptr, c_ptr,
    M, N, K,
    stride_am, stride_ak,
    stride_bk, stride_bn,
    stride_cm, stride_cn,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    BLOCK_SIZE_K: tl.constexpr,
):
    # 内核实现与上面相同
    pass
```

### 实践项目 (2小时)
```python
# 项目：Flash Attention简化实现
@triton.jit
def flash_attention_kernel(
    Q, K, V, O,
    M, N, D,
    stride_qm, stride_qd,
    stride_kn, stride_kd,
    stride_vn, stride_vd,
    stride_om, stride_od,
    BLOCK_M: tl.constexpr,
    BLOCK_N: tl.constexpr,
):
    """Flash Attention内核"""
    pid_m = tl.program_id(0)
    
    # 偏移量
    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = tl.arange(0, BLOCK_N)
    offs_d = tl.arange(0, D)
    
    # Q指针
    q_ptrs = Q + offs_m[:, None] * stride_qm + offs_d[None, :] * stride_qd
    q = tl.load(q_ptrs, mask=offs_m[:, None] < M, other=0.0)
    
    # 初始化输出和统计量
    o_i = tl.zeros([BLOCK_M, D], dtype=tl.float32)
    l_i = tl.zeros([BLOCK_M], dtype=tl.float32)
    m_i = tl.full([BLOCK_M], -float('inf'), dtype=tl.float32)
    
    # N维度循环
    for start_n in range(0, N, BLOCK_N):
        # K和V指针
        k_ptrs = K + (start_n + offs_n)[:, None] * stride_kn + offs_d[None, :] * stride_kd
        v_ptrs = V + (start_n + offs_n)[:, None] * stride_vn + offs_d[None, :] * stride_vd
        
        # 加载K和V
        k = tl.load(k_ptrs, mask=(start_n + offs_n)[:, None] < N, other=0.0)
        v = tl.load(v_ptrs, mask=(start_n + offs_n)[:, None] < N, other=0.0)
        
        # 计算注意力分数
        qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32)
        qk += tl.dot(q, tl.trans(k))
        
        # 更新统计量
        m_ij = tl.max(qk, 1)
        p_ij = tl.exp(qk - m_ij[:, None])
        l_ij = tl.sum(p_ij, 1)
        
        # 更新全局统计量
        m_i_new = tl.maximum(m_i, m_ij)
        alpha = tl.exp(m_i - m_i_new)
        beta = tl.exp(m_ij - m_i_new)
        
        l_i_new = alpha * l_i + beta * l_ij
        
        # 更新输出
        o_i = alpha[:, None] * o_i + beta[:, None] * tl.dot(p_ij, v)
        
        # 更新统计量
        l_i = l_i_new
        m_i = m_i_new
    
    # 最终归一化
    o_i = o_i / l_i[:, None]
    
    # 存储输出
    o_ptrs = O + offs_m[:, None] * stride_om + offs_d[None, :] * stride_od
    tl.store(o_ptrs, o_i.to(tl.float16), mask=offs_m[:, None] < M)

def flash_attention(q, k, v):
    """Flash Attention包装函数"""
    M, D = q.shape
    N, _ = k.shape
    
    o = torch.empty_like(q)
    
    grid = (triton.cdiv(M, 64),)
    
    flash_attention_kernel[grid](
        q, k, v, o,
        M, N, D,
        q.stride(0), q.stride(1),
        k.stride(0), k.stride(1),
        v.stride(0), v.stride(1),
        o.stride(0), o.stride(1),
        BLOCK_M=64, BLOCK_N=64
    )
    
    return o
```

---

## 模块三：PyTorch ATen入门教程

### 快速开始 (30分钟)

#### 自定义Function基础
```python
import torch
from torch.autograd import Function

class SquareFunction(Function):
    """自定义平方函数"""
    
    @staticmethod
    def forward(ctx, input):
        # 保存用于反向传播的张量
        ctx.save_for_backward(input)
        return input ** 2
    
    @staticmethod
    def backward(ctx, grad_output):
        # 恢复保存的张量
        input, = ctx.saved_tensors
        # 计算梯度: d/dx(x²) = 2x
        grad_input = grad_output * 2 * input
        return grad_input

# 使用自定义函数
def square(input):
    return SquareFunction.apply(input)

# 测试
x = torch.tensor([2.0, 3.0], requires_grad=True)
y = square(x)
y.sum().backward()
print("输入:", x)
print("输出:", y)
print("梯度:", x.grad)  # [4.0, 6.0]
```

#### C++扩展快速入门
```python
# setup.py
from setuptools import setup
from pybind11.setup_helpers import Pybind11Extension, build_ext
from torch.utils.cpp_extension import CppExtension

ext_modules = [
    CppExtension(
        'custom_ops',
        ['custom_ops.cpp'],
    ),
]

setup(
    name='custom_ops',
    ext_modules=ext_modules,
    cmdclass={'build_ext': build_ext},
)
```

```cpp
// custom_ops.cpp
#include <torch/extension.h>

torch::Tensor square_forward(torch::Tensor input) {
    return input * input;
}

torch::Tensor square_backward(torch::Tensor grad_output, torch::Tensor input) {
    return grad_output * 2 * input;
}

PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
    m.def("square_forward", &square_forward, "Square forward");
    m.def("square_backward", &square_backward, "Square backward");
}
```

### 核心概念理解 (1小时)

#### 1. 张量的内存布局
```python
import torch

# 创建张量
x = torch.randn(2, 3, 4)
print("原始形状:", x.shape)
print("步长:", x.stride())
print("是否连续:", x.is_contiguous())

# 转置操作
y = x.transpose(1, 2)
print("转置后形状:", y.shape)
print("转置后步长:", y.stride())
print("转置后是否连续:", y.is_contiguous())

# 使连续
z = y.contiguous()
print("连续化后步长:", z.stride())
print("连续化后是否连续:", z.is_contiguous())
```

#### 2. 设备和数据类型
```python
# 设备管理
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
x = torch.randn(1000, 1000, device=device)

# 数据类型转换
x_fp16 = x.half()  # float16
x_int = x.int()    # int32

# 检查属性
print("设备:", x.device)
print("数据类型:", x.dtype)
print("元素总数:", x.numel())
```

#### 3. 自动微分机制
```python
# 梯度计算图
x = torch.tensor([1.0, 2.0], requires_grad=True)
y = torch.tensor([3.0, 4.0], requires_grad=True)

# 前向计算
z = x * y + x ** 2
loss = z.sum()

# 反向传播
loss.backward()

print("x的梯度:", x.grad)  # dL/dx = y + 2*x
print("y的梯度:", y.grad)  # dL/dy = x

# 计算图可视化
print("loss的计算图:")
print("grad_fn:", loss.grad_fn)
print("next_functions:", loss.grad_fn.next_functions)
```

### 实践项目 (2小时)
```python
# 项目：自定义ReLU实现（支持C++后端）
import torch
import torch.nn as nn
from torch.autograd import Function
from torch.utils.cpp_extension import load_inline

# C++实现
cpp_source = """
#include <torch/extension.h>

torch::Tensor relu_forward_cpu(torch::Tensor input) {
    auto output = torch::zeros_like(input);
    auto input_data = input.data_ptr<float>();
    auto output_data = output.data_ptr<float>();
    auto numel = input.numel();
    
    for (int64_t i = 0; i < numel; i++) {
        output_data[i] = std::max(0.0f, input_data[i]);
    }
    
    return output;
}

torch::Tensor relu_backward_cpu(torch::Tensor grad_output, torch::Tensor input) {
    auto grad_input = torch::zeros_like(input);
    auto grad_output_data = grad_output.data_ptr<float>();
    auto input_data = input.data_ptr<float>();
    auto grad_input_data = grad_input.data_ptr<float>();
    auto numel = input.numel();
    
    for (int64_t i = 0; i < numel; i++) {
        grad_input_data[i] = input_data[i] > 0 ? grad_output_data[i] : 0.0f;
    }
    
    return grad_input;
}

PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
    m.def("relu_forward", &relu_forward_cpu, "ReLU forward (CPU)");
    m.def("relu_backward", &relu_backward_cpu, "ReLU backward (CPU)");
}
"""

# 动态编译C++扩展
try:
    relu_cpp = load_inline(
        name='relu_cpp',
        cpp_sources=[cpp_source],
        verbose=True
    )
    HAS_CPP = True
except:
    HAS_CPP = False
    print("C++扩展编译失败，使用Python实现")

class CustomReLU(Function):
    @staticmethod
    def forward(ctx, input):
        ctx.save_for_backward(input)
        
        if HAS_CPP and not input.is_cuda:
            return relu_cpp.relu_forward(input)
        else:
            # Python fallback
            return torch.clamp(input, min=0)
    
    @staticmethod
    def backward(ctx, grad_output):
        input, = ctx.saved_tensors
        
        if HAS_CPP and not input.is_cuda:
            return relu_cpp.relu_backward(grad_output, input)
        else:
            # Python fallback
            return grad_output * (input > 0).float()

class CustomReLULayer(nn.Module):
    def __init__(self):
        super().__init__()
    
    def forward(self, input):
        return CustomReLU.apply(input)

# 性能测试
def benchmark_relu():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    x = torch.randn(1000, 1000, device=device, requires_grad=True)
    
    # PyTorch原生
    torch.cuda.synchronize() if device.type == 'cuda' else None
    start = torch.cuda.Event(enable_timing=True) if device.type == 'cuda' else None
    end = torch.cuda.Event(enable_timing=True) if device.type == 'cuda' else None
    
    if device.type == 'cuda':
        start.record()
    
    for _ in range(100):
        y = torch.relu(x)
        loss = y.sum()
        loss.backward()
        x.grad.zero_()
    
    if device.type == 'cuda':
        end.record()
        torch.cuda.synchronize()
        pytorch_time = start.elapsed_time(end)
    
    # 自定义实现
    custom_relu = CustomReLULayer().to(device)
    x.grad = None
    
    if device.type == 'cuda':
        start.record()
    
    for _ in range(100):
        y = custom_relu(x)
        loss = y.sum()
        loss.backward()
        x.grad.zero_()
    
    if device.type == 'cuda':
        end.record()
        torch.cuda.synchronize()
        custom_time = start.elapsed_time(end)
        
        print(f"PyTorch ReLU: {pytorch_time:.2f} ms")
        print(f"Custom ReLU: {custom_time:.2f} ms")
        print(f"Speedup: {pytorch_time/custom_time:.2f}x")

# 测试
if __name__ == "__main__":
    benchmark_relu()
```

---

## 模块四：TVM入门教程

### 快速开始 (30分钟)

#### 环境搭建和第一个程序
```python
import tvm
from tvm import te
import numpy as np

# 定义计算：向量加法
n = 1024
A = te.placeholder((n,), name="A")
B = te.placeholder((n,), name="B")
C = te.compute(A.shape, lambda i: A[i] + B[i], name="C")

# 创建调度
s = te.create_schedule(C.op)

# 编译
target = tvm.target.Target("llvm")
fadd = tvm.build(s, [A, B, C], target, name="myadd")

# 创建测试数据
ctx = tvm.cpu(0)
a = tvm.nd.array(np.random.uniform(size=n).astype(A.dtype), ctx)
b = tvm.nd.array(np.random.uniform(size=n).astype(B.dtype), ctx)
c = tvm.nd.array(np.zeros(n, dtype=C.dtype), ctx)

# 执行
fadd(a, b, c)

# 验证结果
np.testing.assert_allclose(c.numpy(), a.numpy() + b.numpy())
print("向量加法测试通过!")
```

#### Relay高级IR入门
```python
from tvm import relay
import tvm

# 定义神经网络
def create_simple_network():
    # 输入
    x = relay.var("x", shape=(1, 784), dtype="float32")
    
    # 第一层：全连接
    w1 = relay.var("w1", shape=(784, 128), dtype="float32")
    b1 = relay.var("b1", shape=(128,), dtype="float32")
    dense1 = relay.nn.dense(x, w1)
    bias1 = relay.nn.bias_add(dense1, b1)
    relu1 = relay.nn.relu(bias1)
    
    # 第二层：全连接
    w2 = relay.var("w2", shape=(128, 10), dtype="float32")
    b2 = relay.var("b2", shape=(10,), dtype="float32")
    dense2 = relay.nn.dense(relu1, w2)
    bias2 = relay.nn.bias_add(dense2, b2)
    
    # 创建函数
    func = relay.Function([x, w1, b1, w2, b2], bias2)
    return func

# 编译模型
func = create_simple_network()
mod = tvm.IRModule.from_expr(func)
target = tvm.target.Target("llvm")

with tvm.transform.PassContext(opt_level=3):
    lib = relay.build(mod, target=target)

print("模型编译成功!")
```

### 核心概念理解 (1小时)

#### 1. Tensor Expression调度优化
```python
# 矩阵乘法优化示例
M, K, N = 1024, 1024, 1024

# 定义计算
A = te.placeholder((M, K), name="A")
B = te.placeholder((K, N), name="B")
k = te.reduce_axis((0, K), name="k")
C = te.compute((M, N), lambda i, j: te.sum(A[i, k] * B[k, j], axis=k), name="C")

# 基础调度
s = te.create_schedule(C.op)

# 分块优化
xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], 32, 32)

# 并行化
s[C].parallel(xo)

# 向量化
s[C].vectorize(yi)

# 编译并测试性能
func = tvm.build(s, [A, B, C], target="llvm")

# 创建测试数据
ctx = tvm.cpu(0)
a_np = np.random.uniform(size=(M, K)).astype(np.float32)
b_np = np.random.uniform(size=(K, N)).astype(np.float32)

a_tvm = tvm.nd.array(a_np, ctx)
b_tvm = tvm.nd.array(b_np, ctx)
c_tvm = tvm.nd.array(np.zeros((M, N), dtype=np.float32), ctx)

# 性能测试
evaluator = func.time_evaluator(func.entry_name, ctx, number=1)
time_cost = evaluator(a_tvm, b_tvm, c_tvm).mean
print(f"优化后矩阵乘法时间: {time_cost:.6f} 秒")

# 验证正确性
np.testing.assert_allclose(c_tvm.numpy(), np.dot(a_np, b_np), rtol=1e-5)
print("矩阵乘法正确性验证通过!")
```

#### 2. AutoTVM自动调优
```python
from tvm import autotvm

@autotvm.template("tutorial/matrix_multiply")
def matrix_multiply_template(M, K, N, dtype):
    A = te.placeholder((M, K), name="A", dtype=dtype)
    B = te.placeholder((K, N), name="B", dtype=dtype)
    
    # 配置空间
    cfg = autotvm.get_config()
    cfg.define_split("tile_m", M, num_outputs=2)
    cfg.define_split("tile_n", N, num_outputs=2)
    cfg.define_split("tile_k", K, num_outputs=2)
    
    # 定义计算
    k = te.reduce_axis((0, K), name="k")
    C = te.compute((M, N), lambda i, j: te.sum(A[i, k] * B[k, j], axis=k), name="C")
    
    # 应用调度
    s = te.create_schedule(C.op)
    
    # 分块
    mo, mi = cfg["tile_m"].apply(s, C, C.op.axis[0])
    no, ni = cfg["tile_n"].apply(s, C, C.op.axis[1])
    ko, ki = cfg["tile_k"].apply(s, C, k)
    
    # 重排序
    s[C].reorder(mo, no, ko, mi, ni, ki)
    
    return s, [A, B, C]

# 创建调优任务
task = autotvm.task.create("tutorial/matrix_multiply",
                          args=(512, 512, 512, "float32"),
                          target="llvm")

print(f"配置空间大小: {len(task.config_space)}")

# 简化的调优过程（实际使用中需要更多trials）
measure_option = autotvm.measure_option(
    builder=autotvm.LocalBuilder(),
    runner=autotvm.LocalRunner(number=5, repeat=1, timeout=10)
)

tuner = autotvm.tuner.RandomTuner(task)
tuner.tune(n_trial=20, measure_option=measure_option)

# 应用最佳配置
with autotvm.apply_history_best("matrix_multiply.log"):
    with tvm.target.Target("llvm"):
        s, arg_bufs = matrix_multiply_template(512, 512, 512, "float32")
        func = tvm.build(s, arg_bufs)
        
print("自动调优完成!")
```

### 实践项目 (2小时)
```python
# 项目：端到端模型编译和优化
import torch
import torchvision
from tvm import relay
from tvm.contrib import graph_executor

class ModelOptimizer:
    def __init__(self, target="llvm"):
        self.target = tvm.target.Target(target)
        self.ctx = tvm.cpu(0) if target == "llvm" else tvm.cuda(0)
    
    def convert_pytorch_model(self, model, input_shape):
        """将PyTorch模型转换为Relay IR"""
        model.eval()
        
        # 创建示例输入
        input_data = torch.randn(input_shape)
        
        # 跟踪模型
        scripted_model = torch.jit.trace(model, input_data)
        
        # 转换为Relay
        mod, params = relay.frontend.from_pytorch(scripted_model, [("input0", input_shape)])
        
        return mod, params
    
    def optimize_model(self, mod, params):
        """应用图级优化"""
        with tvm.transform.PassContext(opt_level=3):
            # 标准优化passes
            seq = tvm.transform.Sequential([
                relay.transform.RemoveUnusedFunctions(),
                relay.transform.ToBasicBlockNormalForm(),
                relay.transform.EliminateCommonSubexpr(),
                relay.transform.FuseOps(fuse_opt_level=2),
                relay.transform.FoldConstant(),
                relay.transform.CombineParallelConv2D(),
                relay.transform.CombineParallelDense(),
                relay.transform.AlterOpLayout(),
            ])
            
            optimized_mod = seq(mod)
        
        return optimized_mod, params
    
    def compile_model(self, mod, params):
        """编译模型"""
        with tvm.transform.PassContext(opt_level=3):
            lib = relay.build(mod, target=self.target, params=params)
        
        # 创建运行时模块
        module = graph_executor.GraphModule(lib["default"](self.ctx))
        
        return module
    
    def benchmark_model(self, module, input_shape, num_runs=100):
        """性能基准测试"""
        # 创建输入数据
        input_data = np.random.uniform(size=input_shape).astype(np.float32)
        
        # 设置输入
        module.set_input("input0", input_data)
        
        # 预热
        for _ in range(10):
            module.run()
        
        # 测试
        timer = module.module.time_evaluator("run", self.ctx, number=num_runs)
        prof_res = timer()
        
        return prof_res.mean * 1000  # 转换为毫秒

# 使用示例
def main():
    # 创建ResNet18模型
    model = torchvision.models.resnet18(pretrained=False)
    input_shape = (1, 3, 224, 224)
    
    optimizer = ModelOptimizer(target="llvm")
    
    print("1. 转换PyTorch模型...")
    mod, params = optimizer.convert_pytorch_model(model, input_shape)
    
    print("2. 应用图优化...")
    optimized_mod, params = optimizer.optimize_model(mod, params)
    
    print("3. 编译模型...")
    tvm_module = optimizer.compile_model(optimized_mod, params)
    
    print("4. 性能测试...")
    avg_time = optimizer.benchmark_model(tvm_module, input_shape)
    print(f"平均推理时间: {avg_time:.2f} ms")
    
    # 与PyTorch对比
    model.eval()
    input_tensor = torch.randn(input_shape)
    
    import time
    start_time = time.time()
    for _ in range(100):
        with torch.no_grad():
            _ = model(input_tensor)
    pytorch_time = (time.time() - start_time) / 100 * 1000
    
    print(f"PyTorch推理时间: {pytorch_time:.2f} ms")
    print(f"TVM加速比: {pytorch_time/avg_time:.2f}x")

if __name__ == "__main__":
    main()
```

---

## 学习建议和后续规划

### 学习顺序建议
1. **先学习ONNXRuntime** - 建立工业级系统理解
2. **然后学习Triton** - 掌握GPU编程基础  
3. **深入PyTorch ATen** - 理解框架内部机制
4. **最后学习TVM** - 掌握编译器优化技术

### 实践建议
- 每个模块都要完成对应的实践项目
- 尝试将不同技术栈结合使用
- 参与开源社区，贡献代码
- 关注最新的技术发展和论文

### 进阶方向
- 针对特定硬件的算子优化
- 新架构的编译器后端开发
- 模型压缩和量化技术
- 自动化优化工具开发

通过这四个模块的学习，您将建立完整的AI芯片算子开发技术栈，为在这个领域的深入发展奠定坚实基础。
